{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nclhpm/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# or any of these variants\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "#model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.get_device_name(0)\n",
    "#print(\"\\n\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.0977e+00, -1.7348e+00, -2.2355e+00, -2.9669e+00, -2.3805e+00,\n",
      "         9.7397e-01, -1.6049e+00,  3.6914e+00,  6.3812e+00, -1.2929e+00,\n",
      "        -6.7555e+00, -3.3525e+00, -7.9619e+00, -4.4554e+00, -5.6423e+00,\n",
      "        -4.6624e+00, -1.9577e+00, -3.5811e-01, -1.2812e+00, -4.6707e+00,\n",
      "        -3.2935e+00, -2.5674e+00, -2.4351e+00, -1.3017e+00, -3.2453e+00,\n",
      "        -1.4237e+00, -1.2001e+00,  4.1275e-01, -1.6093e+00,  1.5871e+00,\n",
      "         2.7725e-01, -6.2652e-01, -2.9734e-01, -3.8219e+00, -1.5450e+00,\n",
      "        -2.8976e+00, -5.6528e-01, -2.3938e+00, -3.3705e-01,  1.2809e+00,\n",
      "        -1.2516e+00, -2.6469e+00, -3.1011e+00, -2.2447e+00, -4.4385e-01,\n",
      "        -1.2620e+00,  8.2895e-01, -2.0436e+00, -6.6037e-01, -8.6522e-02,\n",
      "         4.8967e-01, -1.7190e+00, -7.7943e-01, -1.1046e+00, -5.3857e-01,\n",
      "        -2.9254e+00, -1.9327e+00, -2.7273e+00, -6.0903e-01, -1.6802e+00,\n",
      "         1.3443e+00, -4.2062e+00, -1.4768e+00, -4.5581e+00, -3.2726e+00,\n",
      "        -4.0086e+00,  1.5702e-01, -1.9921e+00, -7.4553e-01, -4.2230e+00,\n",
      "        -3.8855e+00, -9.4837e-01, -2.1373e+00, -3.5562e+00, -2.4602e+00,\n",
      "        -3.2339e+00, -3.1414e+00, -2.6786e+00, -3.4320e-01,  1.3021e+00,\n",
      "        -1.8081e+00, -6.9590e-01,  6.0993e-01,  1.0629e+00,  7.0008e-01,\n",
      "        -2.1399e+00, -8.3321e-01, -1.2712e+00, -2.9445e+00,  2.6159e+00,\n",
      "        -3.0859e+00, -3.9236e+00, -5.0966e+00, -2.6899e+00, -4.2541e+00,\n",
      "        -5.7496e+00, -1.4612e+00, -3.3379e+00, -5.1146e+00,  1.3199e-01,\n",
      "         6.4283e-01, -3.8178e+00, -6.0667e-01, -3.8236e+00,  8.3375e+00,\n",
      "        -2.0877e-01,  1.5727e+00, -3.2569e+00, -1.3088e+00, -4.3541e+00,\n",
      "        -1.8997e+00, -4.4558e+00, -2.6055e+00, -4.8200e-01,  6.5847e-01,\n",
      "        -1.1139e+00, -1.9922e+00, -2.9861e+00,  6.3544e-02, -4.1179e-02,\n",
      "        -4.9799e+00, -3.5623e-01,  6.9237e-02,  2.6185e-02,  1.0603e+00,\n",
      "        -3.7500e+00, -2.2764e+00, -1.1260e+00, -3.6557e+00, -1.0141e+00,\n",
      "        -3.8173e+00, -2.6216e+00,  8.1061e-01, -4.8440e+00, -1.8047e-01,\n",
      "        -3.7860e+00, -2.7942e+00, -4.0452e+00, -2.7590e+00, -7.6154e+00,\n",
      "        -6.3294e+00, -3.7503e+00, -4.7911e+00, -2.9558e+00, -1.1693e+00,\n",
      "        -1.1443e+00,  4.1418e-01, -2.1690e+00, -2.2886e+00, -1.6754e+00,\n",
      "        -2.3970e+00,  6.1470e+00,  6.3288e+00,  4.1129e+00,  5.7730e+00,\n",
      "         1.3963e+00,  3.3142e-01,  8.0281e+00,  1.5755e+00, -1.1556e-02,\n",
      "         3.4566e-02, -7.4600e-01,  5.0004e-01, -1.5472e+00, -2.2847e+00,\n",
      "        -3.6398e+00, -6.4526e-01, -2.2491e+00,  1.6223e-01,  4.6008e+00,\n",
      "         3.4056e+00,  7.1301e-02, -1.5552e+00,  5.0138e+00,  5.8507e+00,\n",
      "         1.5491e+00, -2.0445e+00,  2.4170e+00, -2.4798e+00,  1.2948e+00,\n",
      "         1.9327e+00, -2.7864e+00,  1.2956e+00,  2.8686e-01,  2.5281e+00,\n",
      "         4.3597e+00,  5.6367e+00, -6.1374e-01,  3.3545e+00, -2.7333e-01,\n",
      "         2.3450e+00, -1.3377e+00,  5.4958e+00,  4.5115e+00,  2.6891e-01,\n",
      "         1.1485e+00, -1.2563e-01,  1.1168e+00,  6.3621e-02,  6.5230e+00,\n",
      "         2.4672e+00,  4.8819e-01, -3.3207e-01,  9.2125e+00,  1.6410e+00,\n",
      "         1.3188e+00,  1.9943e-01,  4.5677e+00,  2.1875e+00,  2.2087e-01,\n",
      "        -2.4104e+00,  6.0055e-01,  3.0084e+00, -5.4444e-01, -1.2983e+00,\n",
      "         2.8078e+00,  1.9668e+00,  2.0604e+00,  7.7009e-01,  1.6875e+00,\n",
      "         1.9477e+00, -7.9099e-01,  7.2126e+00,  9.0092e+00,  8.0076e+00,\n",
      "         2.3563e+00,  3.7544e+00,  5.7382e+00,  3.8081e+00,  6.5486e+00,\n",
      "         9.7228e+00,  1.0013e+01,  9.5305e+00,  2.3904e+00, -5.0376e-01,\n",
      "         5.1103e+00,  5.7609e-01,  1.5447e+00,  1.2857e+00,  3.5652e+00,\n",
      "         2.5450e+00,  1.4888e+00, -8.1306e-01, -2.7417e+00,  8.7089e-01,\n",
      "        -5.8501e-01, -4.0766e-01,  3.2671e+00,  9.6768e+00,  8.9972e+00,\n",
      "         9.2585e+00,  1.4055e+00,  1.1183e-01,  2.6600e+00, -1.4223e+00,\n",
      "         1.1165e+00,  5.2566e+00,  9.9246e+00,  1.4355e+01,  1.1880e+01,\n",
      "         5.9999e+00,  1.0196e+01, -3.5385e-01,  8.2910e+00,  6.0060e+00,\n",
      "         6.8347e-01,  4.1930e-01,  2.0777e+00, -5.5983e-01,  4.8030e+00,\n",
      "         9.0072e+00,  1.7113e+00,  2.3010e+00,  4.5991e+00,  3.6477e+00,\n",
      "        -9.0076e-01,  8.6037e-01,  4.4647e+00,  2.8593e+00,  9.2391e+00,\n",
      "         3.4026e+00,  3.9940e+00,  3.7692e+00,  7.0309e+00,  3.9052e+00,\n",
      "         4.3277e+00, -3.0220e-01,  3.9064e+00,  1.5825e-01,  1.4127e+00,\n",
      "        -2.0500e+00, -1.2154e+00,  1.4670e+00, -1.4580e+00, -1.5738e+00,\n",
      "        -1.3263e+00,  9.2760e-02, -2.6180e+00, -1.4926e-01, -7.5717e-01,\n",
      "        -5.3535e+00, -3.6209e+00, -2.3243e+00, -1.6823e+00, -3.7550e+00,\n",
      "        -3.8941e+00, -7.9254e-01, -1.5161e+00, -5.7227e+00, -2.8694e+00,\n",
      "        -7.2898e-01, -4.1100e-01, -7.2024e-01,  3.7915e-02, -1.0243e+00,\n",
      "        -3.3016e+00, -3.5729e+00, -1.9918e+00, -1.6733e+00, -5.8971e+00,\n",
      "        -5.3597e+00, -3.9750e+00, -3.6543e+00, -4.1491e+00, -2.9045e+00,\n",
      "        -1.0445e+00, -2.6859e+00, -1.9066e+00, -2.3439e+00, -6.2355e-01,\n",
      "         3.5224e+00,  6.2726e+00,  8.5430e+00,  5.0669e+00,  1.8273e+00,\n",
      "         4.6736e+00,  8.4476e-01, -1.9571e-02,  3.3690e+00, -1.0283e-01,\n",
      "        -2.4612e+00,  2.4195e+00, -5.1352e-01, -3.5477e+00, -3.5470e+00,\n",
      "         2.0303e-01, -1.3766e+00, -2.6088e+00,  2.4946e+00, -2.3945e+00,\n",
      "        -1.1865e+00, -4.9946e+00, -3.3072e+00, -4.2007e-01, -3.7238e+00,\n",
      "         5.3880e+00,  3.4567e+00,  1.0361e+00,  3.7673e+00,  4.1483e+00,\n",
      "        -6.8158e-01,  2.9724e+00, -2.6524e-01,  8.0892e-01, -1.7007e+00,\n",
      "        -2.0444e+00, -2.9546e+00, -3.2660e+00, -8.8699e-01, -3.3023e+00,\n",
      "        -3.3806e-01,  1.2563e+00, -8.9535e-01,  1.4541e+00,  9.4996e-01,\n",
      "        -2.0507e+00, -4.4067e+00,  2.2796e+00, -6.8594e-01, -8.8651e-01,\n",
      "         1.5170e+00, -3.8388e-01, -4.0742e-01,  9.6686e-01,  1.2590e+00,\n",
      "        -4.6555e+00, -6.3739e+00,  7.4363e-01, -1.3343e+00, -7.2346e-02,\n",
      "        -2.0423e+00,  3.7000e-01, -3.5627e+00, -1.9930e+00, -1.8647e+00,\n",
      "         1.3201e+00, -3.7614e+00, -2.9709e+00, -1.0222e+00, -1.9434e+00,\n",
      "        -2.9945e+00,  2.2073e-01,  1.7212e+00, -2.3659e+00, -1.2634e+00,\n",
      "        -1.0104e+00, -4.0589e+00,  2.7515e-02,  1.4427e+00,  7.0132e-02,\n",
      "        -3.4568e+00,  1.0521e+00,  3.5129e+00,  6.4661e-01, -1.4407e+00,\n",
      "        -2.4270e-01, -3.5198e+00, -9.4175e-01, -1.0295e+00,  3.3603e-01,\n",
      "         2.0016e-01, -8.9978e-02,  2.2656e-01, -9.6324e-01, -1.7674e+00,\n",
      "         6.4673e-01, -3.3784e-02,  4.2802e+00,  5.3263e+00,  2.2384e+00,\n",
      "        -3.5597e+00,  1.1807e+00,  4.5923e-02, -2.6271e+00,  1.0758e-01,\n",
      "         1.2795e+00,  1.5737e+00,  1.1931e+00, -2.4457e+00, -8.4555e-01,\n",
      "         2.8623e+00,  2.8806e-01, -5.9179e-01, -9.3240e-01,  1.4194e+00,\n",
      "        -1.0869e+00,  8.0467e-01,  2.6026e+00, -1.2723e+00, -7.7225e-01,\n",
      "         2.2809e+00, -1.4838e+00,  5.8848e-01, -9.0864e-01, -2.9350e+00,\n",
      "        -1.5003e+00,  2.7366e+00,  2.9118e+00, -2.5303e-01, -1.1096e+00,\n",
      "         2.3799e+00,  7.6073e-01,  5.4272e+00,  4.6897e+00, -1.3155e-01,\n",
      "        -8.0122e-01, -3.1159e+00, -4.0464e+00,  6.5657e-01,  2.0462e+00,\n",
      "         2.7152e+00,  2.0442e+00,  1.9868e+00, -1.4363e+00, -2.0505e+00,\n",
      "        -1.6228e+00, -7.0752e-01,  6.1674e-01,  2.5873e+00,  2.1843e+00,\n",
      "        -6.1809e-01, -1.9566e+00, -8.5768e-01,  7.1875e-01,  2.1852e+00,\n",
      "         2.9276e-01, -2.9160e+00,  4.7730e-01,  2.0784e+00,  4.0771e+00,\n",
      "        -2.4195e-01,  1.3048e+00, -5.0637e-01, -3.4089e-01,  6.6665e-01,\n",
      "        -1.1453e+00,  1.2197e+00, -1.6476e+00,  1.0244e+00, -1.2750e-02,\n",
      "        -3.8730e+00,  1.3927e+00,  3.1080e+00,  2.1766e+00,  1.2399e-02,\n",
      "         8.3346e-01,  6.3474e-01,  6.4802e-01,  1.8221e+00, -2.7608e+00,\n",
      "        -3.6870e+00,  1.3747e+00,  9.1805e-02,  8.2601e-01, -1.5124e+00,\n",
      "         2.2673e+00,  1.3142e-01, -2.9091e+00, -1.5961e-01,  2.5890e+00,\n",
      "        -1.2447e+00, -1.2865e+00,  5.8338e+00,  1.6895e+00, -2.0549e-01,\n",
      "        -1.0211e+00, -2.4552e+00, -5.0936e-01, -5.2974e-01, -4.5987e-01,\n",
      "         2.6499e-01, -2.9162e+00, -3.0222e+00,  2.2564e-01,  1.5582e+00,\n",
      "        -1.2585e-01, -1.8132e+00,  2.3502e+00, -3.3209e+00,  4.9566e+00,\n",
      "        -4.9510e+00, -7.4566e-01,  2.1571e+00,  7.6538e-01,  2.0662e+00,\n",
      "         1.6266e+00, -1.2199e-01, -4.3637e+00, -2.1941e+00, -3.0787e-01,\n",
      "        -3.8238e+00, -1.6580e+00,  4.3411e+00,  2.7014e-01, -3.5598e-01,\n",
      "        -2.5363e-01, -4.9810e-01,  2.2959e+00,  2.2455e+00,  8.4955e-01,\n",
      "        -9.5632e-01, -1.0925e-02,  2.0118e-01,  6.2614e-01, -2.0728e+00,\n",
      "        -2.8902e+00,  1.5548e+00,  7.2548e-01, -1.0286e+00,  4.4619e-02,\n",
      "        -1.0328e+00, -6.0998e-02,  8.5732e-02,  2.3276e+00,  2.5550e+00,\n",
      "         1.4773e+00, -2.1379e+00,  8.2632e-01,  9.0537e-01,  5.8717e-01,\n",
      "         1.4047e-01,  1.2880e+00, -1.2447e+00, -3.0260e+00,  1.3479e+00,\n",
      "         6.5378e-01,  1.0272e+00,  1.3767e+00,  1.0319e+00,  4.7779e-01,\n",
      "         5.2349e-01, -8.8269e-01, -1.4962e+00, -1.1824e+00,  1.1073e+00,\n",
      "        -2.2532e+00,  2.1382e+00,  9.7307e-01, -1.0084e+00, -1.6575e+00,\n",
      "        -9.5915e-04,  1.6627e+00, -2.1514e+00, -2.3709e+00, -3.4100e+00,\n",
      "        -5.2928e-01,  1.9259e-01, -8.0650e-01,  1.6568e+00, -5.1726e-01,\n",
      "        -1.5838e-01, -8.9716e-01, -4.5829e+00,  1.4675e+00, -4.5201e-01,\n",
      "         1.2436e+00,  6.0141e-01, -3.8649e-01, -1.7420e+00, -1.5792e+00,\n",
      "         9.3821e-01,  4.2496e+00,  1.1979e+00, -2.4132e-01, -3.2378e+00,\n",
      "        -1.0954e+00, -9.6520e-02,  1.8683e+00,  1.1284e+00,  2.0860e+00,\n",
      "         9.5167e-01,  1.8403e+00,  2.5347e-01,  1.8567e-01, -1.2812e+00,\n",
      "        -6.6936e-01,  2.0522e+00,  1.4342e+00, -2.2879e-01, -8.0857e-01,\n",
      "         1.9737e+00,  1.1951e+00, -8.6991e-01, -6.7025e-01,  5.4059e-01,\n",
      "        -4.6110e-01,  2.6557e+00, -1.3025e+00, -1.6542e+00, -1.3156e+00,\n",
      "         3.2369e-01, -5.4370e-01,  1.6666e+00,  4.5700e+00, -2.3573e+00,\n",
      "         1.2469e+00,  1.1997e+00,  4.0686e+00, -7.7611e-03, -1.1327e+00,\n",
      "         1.3139e+00, -3.5417e-01, -6.1601e-01, -3.9956e+00,  1.6335e+00,\n",
      "        -1.0202e+00, -4.5716e-01,  5.7760e-01, -3.4985e+00, -1.1559e-01,\n",
      "        -4.9487e-01,  6.6963e-01, -6.2700e-01,  1.0441e+00,  3.0509e+00,\n",
      "        -3.1207e-01,  2.7649e+00,  6.2701e-01, -1.7978e+00, -2.0636e+00,\n",
      "         6.7860e-01,  1.0197e-01, -1.0705e+00,  3.0527e-01, -1.7576e+00,\n",
      "         1.1912e+00, -2.5650e+00, -2.0395e+00, -2.3386e-02, -6.6742e-01,\n",
      "        -1.3196e+00, -1.5473e+00,  1.4445e+00,  4.8465e-01, -2.8597e-01,\n",
      "         2.0573e+00,  1.8837e+00, -4.4886e-01, -5.9843e-01,  1.4961e+00,\n",
      "         4.2709e+00,  4.7193e-02, -3.9729e+00,  1.6866e+00,  1.1838e-01,\n",
      "        -2.1901e+00, -1.4564e+00,  6.3495e-01, -6.9223e-02, -1.1540e-01,\n",
      "        -2.6747e+00, -1.8754e+00, -3.3247e-02, -1.3887e+00, -5.8239e-01,\n",
      "        -2.6332e+00,  2.9077e+00,  7.7976e-01,  1.2104e+00,  1.8161e+00,\n",
      "        -1.2151e+00,  1.0008e+00,  2.1955e+00,  3.8305e+00, -1.8397e+00,\n",
      "         5.7437e-01, -3.9989e+00, -2.8352e-01,  2.3984e+00, -1.1624e+00,\n",
      "         7.7795e-01,  4.9292e+00, -1.8727e+00,  4.6069e+00, -4.2315e+00,\n",
      "         2.9490e-01, -2.9247e+00, -4.1031e-01, -2.6956e-01, -3.2782e+00,\n",
      "         5.1225e-02, -1.1451e+00,  1.9002e+00, -3.3774e+00,  3.5610e+00,\n",
      "        -5.8406e-01, -2.5784e-01,  2.5958e+00,  4.8148e-01,  3.4009e+00,\n",
      "         1.9466e+00,  4.3969e+00,  3.1025e+00,  1.8707e+00,  2.3226e+00,\n",
      "        -1.7758e+00,  4.5991e+00, -3.1057e-01,  2.5523e+00, -4.3005e-01,\n",
      "         1.1663e+00,  3.7423e+00, -3.3202e+00,  2.9863e+00,  2.3991e+00,\n",
      "         1.8163e+00,  6.2834e-01, -3.0631e+00,  1.3832e+00,  2.3446e-01,\n",
      "         4.5703e-01, -5.2095e-01, -6.3540e-01, -2.3105e+00, -9.3955e-02,\n",
      "         4.7082e-01, -4.4529e-01,  3.7371e-01, -1.8174e+00, -1.6152e+00,\n",
      "        -3.7139e-01, -5.7884e-01,  1.7545e+00,  7.7587e-01, -7.8314e-02,\n",
      "         1.6372e-02, -2.9957e+00,  1.5097e+00, -1.9589e+00, -2.1457e+00,\n",
      "         8.6147e-01,  1.3731e+00,  4.8385e+00,  1.1895e+00, -5.1669e-02,\n",
      "        -6.9186e-01, -2.4000e+00,  2.2452e+00, -2.8816e+00,  2.9604e-01,\n",
      "        -2.4873e-02, -1.6365e+00,  5.4108e-01,  7.9194e-01, -4.7307e-01,\n",
      "         3.3787e+00,  3.1170e-01, -4.7706e-01,  4.7993e-01, -2.1351e+00,\n",
      "        -1.1842e+00,  2.8761e+00, -2.5128e+00,  6.7475e-01,  4.2304e-01,\n",
      "        -1.5112e-01, -2.4046e-01,  2.6086e+00,  2.2590e+00, -1.3191e+00,\n",
      "        -1.4585e+00, -1.7858e-01,  2.4934e-02,  3.6163e+00,  1.1935e+00,\n",
      "         1.5226e+00,  1.1416e+00,  1.3794e+00,  1.2284e+00, -3.1586e+00,\n",
      "         1.8730e+00,  5.6497e-01,  3.5441e-01,  3.7591e+00, -7.5653e-01,\n",
      "         1.4521e+00,  9.2728e-01,  1.7928e+00,  1.3086e+00,  3.3281e-01,\n",
      "         2.5021e+00,  1.2360e-01, -1.9837e+00, -1.9212e+00,  2.2389e+00,\n",
      "         1.7770e+00, -1.0251e+00,  1.1154e+00, -5.6650e-01,  8.5460e-01,\n",
      "        -9.2451e-01,  1.7175e+00,  5.5464e+00, -1.1396e+00, -1.0508e+00,\n",
      "         9.4548e-01, -1.1248e+00, -4.1178e+00, -1.5001e+00, -2.4440e+00,\n",
      "        -2.2460e+00,  2.9526e-01,  6.0925e-02, -6.5614e-02, -3.6811e-01,\n",
      "        -3.9457e+00, -2.5774e-01,  1.0757e+00,  2.7218e-01,  1.2959e-01,\n",
      "         2.9834e+00,  1.5601e+00, -1.3121e+00, -3.4189e+00, -4.8114e+00,\n",
      "        -7.6686e-02,  2.9641e+00, -1.4930e+00, -1.4022e+00,  3.6878e+00,\n",
      "         2.2555e+00,  2.3702e-01,  3.8400e+00, -5.7366e-01, -2.9713e+00,\n",
      "        -1.8238e+00, -2.4696e-01, -5.4835e+00, -1.7653e+00, -1.3388e-01,\n",
      "        -3.1702e+00, -1.5837e+00, -6.3625e-01, -4.9745e-01, -1.8403e+00,\n",
      "         1.0520e+00,  1.6680e+00,  1.8475e+00,  4.0332e+00,  1.3918e+00,\n",
      "        -3.2777e+00, -4.6016e-01,  1.0744e+00, -3.8842e-01,  2.3637e+00,\n",
      "        -5.5235e-02, -1.5774e-01,  1.7894e+00,  8.5379e-01,  6.7841e-01,\n",
      "         7.2238e-01,  7.0537e-01,  3.4570e+00,  3.3763e-01, -1.2732e+00,\n",
      "        -1.6014e+00, -1.1200e-01, -5.0247e+00, -9.6371e-01, -2.9871e-01,\n",
      "        -5.2167e-01, -2.2425e+00, -3.0319e+00, -1.8120e-01, -1.8274e+00,\n",
      "        -2.9185e+00, -5.3206e+00, -4.1687e-01, -1.1471e+00,  4.0239e+00,\n",
      "         1.6161e+00, -7.2602e-01,  2.2094e+00, -3.8633e+00, -2.6026e-01,\n",
      "         1.3907e+00,  2.0413e+00,  1.4310e+00, -5.5395e-01,  8.4763e-01,\n",
      "         1.2557e+00, -2.3636e+00,  5.4900e-01,  2.3557e-01, -2.1998e+00,\n",
      "        -3.3631e+00, -2.3922e+00, -1.7042e+00,  2.6087e+00,  1.6107e+00,\n",
      "        -3.4292e-01, -4.9724e-01, -3.1873e+00, -4.1049e-01, -1.3927e+00,\n",
      "        -3.3978e-01, -1.3094e+00,  3.4262e-01,  2.9870e+00, -1.0335e+00,\n",
      "        -5.0580e-01,  7.1299e-01, -1.3783e+00, -2.2482e+00, -3.8999e+00,\n",
      "        -2.0363e+00,  1.1213e+00, -4.8775e+00,  3.2949e-01,  1.5133e+00,\n",
      "         1.1563e+00,  2.0571e+00,  5.9265e-01, -3.9987e+00, -7.2273e-01,\n",
      "         2.9365e+00, -1.7806e+00,  1.8060e+00, -2.9915e-01, -1.3354e+00,\n",
      "         4.0328e-01,  1.8248e-02, -1.7064e-01, -2.5046e+00, -2.3489e-01,\n",
      "        -5.1013e-01, -7.8851e-01,  1.9875e+00, -2.5939e-01, -2.7370e+00,\n",
      "         6.9350e-01, -1.7628e+00, -5.1118e-01, -6.8332e+00, -4.1562e+00,\n",
      "        -2.5831e+00, -1.4274e+00, -3.0766e+00,  1.6652e+00,  3.3317e+00])\n",
      "tensor([3.9432e-06, 8.5398e-08, 5.1760e-08, 2.4907e-08, 4.4774e-08, 1.2818e-06,\n",
      "        9.7240e-08, 1.9409e-05, 2.8588e-04, 1.3284e-07, 5.6362e-10, 1.6938e-08,\n",
      "        1.6867e-10, 5.6221e-09, 1.7157e-09, 4.5706e-09, 6.8331e-08, 3.3831e-07,\n",
      "        1.3440e-07, 4.5330e-09, 1.7967e-08, 3.7139e-08, 4.2395e-08, 1.3168e-07,\n",
      "        1.8854e-08, 1.1656e-07, 1.4577e-07, 7.3130e-07, 9.6811e-08, 2.3665e-06,\n",
      "        6.3863e-07, 2.5867e-07, 3.5951e-07, 1.0593e-08, 1.0324e-07, 2.6695e-08,\n",
      "        2.7501e-07, 4.4179e-08, 3.4552e-07, 1.7424e-06, 1.3845e-07, 3.4300e-08,\n",
      "        2.1779e-08, 5.1287e-08, 3.1052e-07, 1.3701e-07, 1.1088e-06, 6.2706e-08,\n",
      "        2.5006e-07, 4.4388e-07, 7.8978e-07, 8.6757e-08, 2.2200e-07, 1.6037e-07,\n",
      "        2.8245e-07, 2.5964e-08, 7.0061e-08, 3.1653e-08, 2.6324e-07, 9.0184e-08,\n",
      "        1.8563e-06, 7.2130e-09, 1.1052e-07, 5.0733e-09, 1.8347e-08, 8.7891e-09,\n",
      "        5.6629e-07, 6.6023e-08, 2.2965e-07, 7.0927e-09, 9.9400e-09, 1.8749e-07,\n",
      "        5.7097e-08, 1.3817e-08, 4.1344e-08, 1.9071e-08, 2.0919e-08, 3.3230e-08,\n",
      "        3.4339e-07, 1.7796e-06, 7.9357e-08, 2.4133e-07, 8.9070e-07, 1.4011e-06,\n",
      "        9.7473e-07, 5.6951e-08, 2.1037e-07, 1.3576e-07, 2.5472e-08, 6.6207e-06,\n",
      "        2.2114e-08, 9.5690e-09, 2.9609e-09, 3.2859e-08, 6.8756e-09, 1.5411e-09,\n",
      "        1.1226e-07, 1.7188e-08, 2.9081e-09, 5.5229e-07, 9.2050e-07, 1.0636e-08,\n",
      "        2.6386e-07, 1.0575e-08, 2.0220e-03, 3.9280e-07, 2.3327e-06, 1.8638e-08,\n",
      "        1.3075e-07, 6.2214e-09, 7.2416e-08, 5.6197e-09, 3.5750e-08, 2.9889e-07,\n",
      "        9.3501e-07, 1.5889e-07, 6.6013e-08, 2.4435e-08, 5.1575e-07, 4.6447e-07,\n",
      "        3.3275e-09, 3.3895e-07, 5.1870e-07, 4.9684e-07, 1.3974e-06, 1.1383e-08,\n",
      "        4.9683e-08, 1.5698e-07, 1.2508e-08, 1.7556e-07, 1.0642e-08, 3.5180e-08,\n",
      "        1.0886e-06, 3.8115e-09, 4.0408e-07, 1.0980e-08, 2.9602e-08, 8.4727e-09,\n",
      "        3.0664e-08, 2.3852e-10, 8.6299e-10, 1.1379e-08, 4.0188e-09, 2.5185e-08,\n",
      "        1.5032e-07, 1.5413e-07, 7.3236e-07, 5.5319e-08, 4.9083e-08, 9.0621e-08,\n",
      "        4.4039e-08, 2.2618e-04, 2.7128e-04, 2.9585e-05, 1.5561e-04, 1.9554e-06,\n",
      "        6.7419e-07, 1.4839e-03, 2.3392e-06, 4.7844e-07, 5.0102e-07, 2.2954e-07,\n",
      "        7.9801e-07, 1.0301e-07, 4.9273e-08, 1.2709e-08, 2.5387e-07, 5.1061e-08,\n",
      "        5.6925e-07, 4.8191e-05, 1.4584e-05, 5.1977e-07, 1.0219e-07, 7.2828e-05,\n",
      "        1.6818e-04, 2.2783e-06, 6.2654e-08, 5.4267e-06, 4.0539e-08, 1.7667e-06,\n",
      "        3.3434e-06, 2.9834e-08, 1.7682e-06, 6.4480e-07, 6.0646e-06, 3.7864e-05,\n",
      "        1.3578e-04, 2.6200e-07, 1.3857e-05, 3.6825e-07, 5.0495e-06, 1.2702e-07,\n",
      "        1.1793e-04, 4.4071e-05, 6.3333e-07, 1.5263e-06, 4.2686e-07, 1.4787e-06,\n",
      "        5.1579e-07, 3.2941e-04, 5.7060e-06, 7.8861e-07, 3.4724e-07, 4.8504e-03,\n",
      "        2.4977e-06, 1.8096e-06, 5.9082e-07, 4.6619e-05, 4.3138e-06, 6.0363e-07,\n",
      "        4.3455e-08, 8.8239e-07, 9.8035e-06, 2.8080e-07, 1.3212e-07, 8.0218e-06,\n",
      "        3.4595e-06, 3.7991e-06, 1.0454e-06, 2.6164e-06, 3.3942e-06, 2.1944e-07,\n",
      "        6.5653e-04, 3.9582e-03, 1.4537e-03, 5.1072e-06, 2.0670e-05, 1.5028e-04,\n",
      "        2.1811e-05, 3.3795e-04, 8.0800e-03, 1.0798e-02, 6.6662e-03, 5.2841e-06,\n",
      "        2.9246e-07, 8.0211e-05, 8.6106e-07, 2.2683e-06, 1.7506e-06, 1.7107e-05,\n",
      "        6.1678e-06, 2.1450e-06, 2.1465e-07, 3.1199e-08, 1.1563e-06, 2.6964e-07,\n",
      "        3.2196e-07, 1.2697e-05, 7.7165e-03, 3.9110e-03, 5.0790e-03, 1.9735e-06,\n",
      "        5.4127e-07, 6.9190e-06, 1.1672e-07, 1.4783e-06, 9.2845e-05, 9.8867e-03,\n",
      "        8.3030e-01, 6.9888e-02, 1.9524e-04, 1.2964e-02, 3.3976e-07, 1.9302e-03,\n",
      "        1.9643e-04, 9.5868e-07, 7.3612e-07, 3.8653e-06, 2.7651e-07, 5.8987e-05,\n",
      "        3.9501e-03, 2.6796e-06, 4.8325e-06, 4.8105e-05, 1.8579e-05, 1.9663e-07,\n",
      "        1.1442e-06, 4.2057e-05, 8.4457e-06, 4.9811e-03, 1.4540e-05, 2.6267e-05,\n",
      "        2.0979e-05, 5.4742e-04, 2.4036e-05, 3.6672e-05, 3.5777e-07, 2.4065e-05,\n",
      "        5.6698e-07, 1.9878e-06, 6.2310e-08, 1.4355e-07, 2.0988e-06, 1.1262e-07,\n",
      "        1.0031e-07, 1.2849e-07, 5.3104e-07, 3.5308e-08, 4.1689e-07, 2.2699e-07,\n",
      "        2.2900e-09, 1.2952e-08, 4.7359e-08, 8.9996e-08, 1.1326e-08, 9.8554e-09,\n",
      "        2.1910e-07, 1.0627e-07, 1.5832e-09, 2.7458e-08, 2.3348e-07, 3.2088e-07,\n",
      "        2.3553e-07, 5.0270e-07, 1.7378e-07, 1.7823e-08, 1.3587e-08, 6.6044e-08,\n",
      "        9.0809e-08, 1.3298e-09, 2.2759e-09, 9.0891e-09, 1.2525e-08, 7.6370e-09,\n",
      "        2.6513e-08, 1.7030e-07, 3.2988e-08, 7.1918e-08, 4.6442e-08, 2.5944e-07,\n",
      "        1.6392e-05, 2.5645e-04, 2.4833e-03, 7.6799e-05, 3.0090e-06, 5.1825e-05,\n",
      "        1.1265e-06, 4.7462e-07, 1.4060e-05, 4.3670e-07, 4.1302e-08, 5.4400e-06,\n",
      "        2.8962e-07, 1.3935e-08, 1.3944e-08, 5.9296e-07, 1.2218e-07, 3.5634e-08,\n",
      "        5.8646e-06, 4.4152e-08, 1.4776e-07, 3.2789e-09, 1.7723e-08, 3.1799e-07,\n",
      "        1.1685e-08, 1.0588e-04, 1.5348e-05, 1.3640e-06, 2.0940e-05, 3.0651e-05,\n",
      "        2.4482e-07, 9.4564e-06, 3.7124e-07, 1.0868e-06, 8.8361e-08, 6.2655e-08,\n",
      "        2.5217e-08, 1.8470e-08, 1.9936e-07, 1.7811e-08, 3.4516e-07, 1.7000e-06,\n",
      "        1.9770e-07, 2.0719e-06, 1.2514e-06, 6.2263e-08, 5.9024e-09, 4.7301e-06,\n",
      "        2.4375e-07, 1.9945e-07, 2.2064e-06, 3.2971e-07, 3.2204e-07, 1.2728e-06,\n",
      "        1.7046e-06, 4.6026e-09, 8.2546e-10, 1.0181e-06, 1.2746e-07, 4.5022e-07,\n",
      "        6.2792e-08, 7.0070e-07, 1.3727e-08, 6.5961e-08, 7.4989e-08, 1.8120e-06,\n",
      "        1.1253e-08, 2.4808e-08, 1.7414e-07, 6.9313e-08, 2.4229e-08, 6.0354e-07,\n",
      "        2.7061e-06, 4.5430e-08, 1.3682e-07, 1.7621e-07, 8.3577e-09, 4.9750e-07,\n",
      "        2.0484e-06, 5.1916e-07, 1.5261e-08, 1.3860e-06, 1.6236e-05, 9.2399e-07,\n",
      "        1.1459e-07, 3.7970e-07, 1.4329e-08, 1.8873e-07, 1.7288e-07, 6.7730e-07,\n",
      "        5.9125e-07, 4.4235e-07, 6.0707e-07, 1.8472e-07, 8.2659e-08, 9.2409e-07,\n",
      "        4.6792e-07, 3.4972e-05, 9.9546e-05, 4.5393e-06, 1.3768e-08, 1.5762e-06,\n",
      "        5.0674e-07, 3.4988e-08, 5.3897e-07, 1.7399e-06, 2.3351e-06, 1.5959e-06,\n",
      "        4.1946e-08, 2.0779e-07, 8.4711e-06, 6.4557e-07, 2.6782e-07, 1.9051e-07,\n",
      "        2.0012e-06, 1.6324e-07, 1.0822e-06, 6.5337e-06, 1.3561e-07, 2.2360e-07,\n",
      "        4.7360e-06, 1.0976e-07, 8.7181e-07, 1.9509e-07, 2.5715e-08, 1.0796e-07,\n",
      "        7.4701e-06, 8.9006e-06, 3.7580e-07, 1.5957e-07, 5.2289e-06, 1.0357e-06,\n",
      "        1.1012e-04, 5.2670e-05, 4.2434e-07, 2.1721e-07, 2.1461e-08, 8.4629e-09,\n",
      "        9.3323e-07, 3.7454e-06, 7.3124e-06, 3.7377e-06, 3.5295e-06, 1.1510e-07,\n",
      "        6.2278e-08, 9.5511e-08, 2.3855e-07, 8.9679e-07, 6.4344e-06, 4.3001e-06,\n",
      "        2.6086e-07, 6.8410e-08, 2.0529e-07, 9.9310e-07, 4.3038e-06, 6.4862e-07,\n",
      "        2.6209e-08, 7.8007e-07, 3.8681e-06, 2.8545e-05, 3.7998e-07, 1.7844e-06,\n",
      "        2.9170e-07, 3.4419e-07, 9.4268e-07, 1.5397e-07, 1.6388e-06, 9.3177e-08,\n",
      "        1.3482e-06, 4.7787e-07, 1.0065e-08, 1.9485e-06, 1.0830e-05, 4.2672e-06,\n",
      "        4.9004e-07, 1.1138e-06, 9.1308e-07, 9.2529e-07, 2.9936e-06, 3.0609e-08,\n",
      "        1.2123e-08, 1.9136e-06, 5.3054e-07, 1.1055e-06, 1.0666e-07, 4.6723e-06,\n",
      "        5.5198e-07, 2.6389e-08, 4.1260e-07, 6.4450e-06, 1.3940e-07, 1.3370e-07,\n",
      "        1.6536e-04, 2.6218e-06, 3.9410e-07, 1.7433e-07, 4.1548e-08, 2.9083e-07,\n",
      "        2.8496e-07, 3.0558e-07, 6.3085e-07, 2.6203e-08, 2.3568e-08, 6.0651e-07,\n",
      "        2.2991e-06, 4.2677e-07, 7.8954e-08, 5.0758e-06, 1.7481e-08, 6.8779e-05,\n",
      "        3.4250e-09, 2.2962e-07, 4.1847e-06, 1.0405e-06, 3.8209e-06, 2.4618e-06,\n",
      "        4.2841e-07, 6.1617e-09, 5.3948e-08, 3.5574e-07, 1.0572e-08, 9.2213e-08,\n",
      "        3.7167e-05, 6.3411e-07, 3.3903e-07, 3.7557e-07, 2.9412e-07, 4.8078e-06,\n",
      "        4.5712e-06, 1.1319e-06, 1.8600e-07, 4.7874e-07, 5.9186e-07, 9.0526e-07,\n",
      "        6.0906e-08, 2.6893e-08, 2.2913e-06, 9.9981e-07, 1.7304e-07, 5.0608e-07,\n",
      "        1.7231e-07, 4.5536e-07, 5.2732e-07, 4.9626e-06, 6.2295e-06, 2.1205e-06,\n",
      "        5.7065e-08, 1.1059e-06, 1.1969e-06, 8.7066e-07, 5.5699e-07, 1.7548e-06,\n",
      "        1.3940e-07, 2.3478e-08, 1.8630e-06, 9.3063e-07, 1.3520e-06, 1.9176e-06,\n",
      "        1.3583e-06, 7.8045e-07, 8.1695e-07, 2.0022e-07, 1.0841e-07, 1.4837e-07,\n",
      "        1.4647e-06, 5.0849e-08, 4.1064e-06, 1.2807e-06, 1.7657e-07, 9.2259e-08,\n",
      "        4.8354e-07, 2.5524e-06, 5.6300e-08, 4.5202e-08, 1.5991e-08, 2.8509e-07,\n",
      "        5.8679e-07, 2.1607e-07, 2.5374e-06, 2.8854e-07, 4.1311e-07, 1.9734e-07,\n",
      "        4.9488e-09, 2.0997e-06, 3.0799e-07, 1.6786e-06, 8.8315e-07, 3.2885e-07,\n",
      "        8.4783e-08, 9.9775e-08, 1.2368e-06, 3.3919e-05, 1.6036e-06, 3.8022e-07,\n",
      "        1.8996e-08, 1.6186e-07, 4.3947e-07, 3.1349e-06, 1.4959e-06, 3.8973e-06,\n",
      "        1.2536e-06, 3.0484e-06, 6.2363e-07, 5.8275e-07, 1.3441e-07, 2.4783e-07,\n",
      "        3.7679e-06, 2.0309e-06, 3.8502e-07, 2.1562e-07, 3.4836e-06, 1.5991e-06,\n",
      "        2.0279e-07, 2.4760e-07, 8.3103e-07, 3.0521e-07, 6.8899e-06, 1.3158e-07,\n",
      "        9.2565e-08, 1.2987e-07, 6.6899e-07, 2.8101e-07, 2.5624e-06, 4.6729e-05,\n",
      "        4.5822e-08, 1.6842e-06, 1.6064e-06, 2.8301e-05, 4.8026e-07, 1.5593e-07,\n",
      "        1.8008e-06, 3.3965e-07, 2.6141e-07, 8.9039e-09, 2.4790e-06, 1.7449e-07,\n",
      "        3.0641e-07, 8.6237e-07, 1.4638e-08, 4.3116e-07, 2.9507e-07, 9.4550e-07,\n",
      "        2.5855e-07, 1.3750e-06, 1.0229e-05, 3.5425e-07, 7.6847e-06, 9.0605e-07,\n",
      "        8.0180e-08, 6.1466e-08, 9.5401e-07, 5.3595e-07, 1.6593e-07, 6.5678e-07,\n",
      "        8.3473e-08, 1.5929e-06, 3.7230e-08, 6.2966e-08, 4.7281e-07, 2.4831e-07,\n",
      "        1.2934e-07, 1.0300e-07, 2.0521e-06, 7.8583e-07, 3.6362e-07, 3.7873e-06,\n",
      "        3.1835e-06, 3.0896e-07, 2.6604e-07, 2.1607e-06, 3.4649e-05, 5.0739e-07,\n",
      "        9.1085e-09, 2.6142e-06, 5.4483e-07, 5.4164e-08, 1.1281e-07, 9.1327e-07,\n",
      "        4.5163e-07, 4.3125e-07, 3.3360e-08, 7.4190e-08, 4.6817e-07, 1.2071e-07,\n",
      "        2.7034e-07, 3.4775e-08, 8.8644e-06, 1.0556e-06, 1.6237e-06, 2.9757e-06,\n",
      "        1.4359e-07, 1.3166e-06, 4.3485e-06, 2.2305e-05, 7.6890e-08, 8.5959e-07,\n",
      "        8.8747e-09, 3.6451e-07, 5.3267e-06, 1.5136e-07, 1.0537e-06, 6.6922e-05,\n",
      "        7.4395e-08, 4.8483e-05, 7.0330e-09, 6.5001e-07, 2.5980e-08, 3.2111e-07,\n",
      "        3.6964e-07, 1.8244e-08, 5.0944e-07, 1.5400e-07, 3.2367e-06, 1.6521e-08,\n",
      "        1.7035e-05, 2.6989e-07, 3.7399e-07, 6.4892e-06, 7.8334e-07, 1.4516e-05,\n",
      "        3.3903e-06, 3.9301e-05, 1.0771e-05, 3.1425e-06, 4.9378e-06, 8.1966e-08,\n",
      "        4.8106e-05, 3.5479e-07, 6.2126e-06, 3.1483e-07, 1.5537e-06, 2.0423e-05,\n",
      "        1.7494e-08, 9.5895e-06, 5.3306e-06, 2.9761e-06, 9.0725e-07, 2.2622e-08,\n",
      "        1.9300e-06, 6.1188e-07, 7.6441e-07, 2.8747e-07, 2.5639e-07, 4.8020e-08,\n",
      "        4.4060e-07, 7.7503e-07, 3.1007e-07, 7.0330e-07, 7.8625e-08, 9.6246e-08,\n",
      "        3.3385e-07, 2.7131e-07, 2.7978e-06, 1.0515e-06, 4.4754e-07, 4.9199e-07,\n",
      "        2.4201e-08, 2.1902e-06, 6.8253e-08, 5.6619e-08, 1.1454e-06, 1.9107e-06,\n",
      "        6.1120e-05, 1.5901e-06, 4.5963e-07, 2.4231e-07, 4.3907e-08, 4.5700e-06,\n",
      "        2.7126e-08, 6.5075e-07, 4.7211e-07, 9.4213e-08, 8.3144e-07, 1.0685e-06,\n",
      "        3.0157e-07, 1.4197e-05, 6.6102e-07, 3.0037e-07, 7.8212e-07, 5.7222e-08,\n",
      "        1.4809e-07, 8.5883e-06, 3.9222e-08, 9.5035e-07, 7.3887e-07, 4.1611e-07,\n",
      "        3.8055e-07, 6.5726e-06, 4.6336e-06, 1.2941e-07, 1.1257e-07, 4.0485e-07,\n",
      "        4.9622e-07, 1.8005e-05, 1.5965e-06, 2.2188e-06, 1.5157e-06, 1.9226e-06,\n",
      "        1.6532e-06, 2.0562e-08, 3.1499e-06, 8.5155e-07, 6.8987e-07, 2.0769e-05,\n",
      "        2.2714e-07, 2.0677e-06, 1.2234e-06, 2.9070e-06, 1.7912e-06, 6.7512e-07,\n",
      "        5.9087e-06, 5.4767e-07, 6.6580e-08, 7.0871e-08, 4.5414e-06, 2.8613e-06,\n",
      "        1.7365e-07, 1.4766e-06, 2.7467e-07, 1.1376e-06, 1.9202e-07, 2.6962e-06,\n",
      "        1.2406e-04, 1.5485e-07, 1.6923e-07, 1.2458e-06, 1.5717e-07, 7.8793e-09,\n",
      "        1.0798e-07, 4.2017e-08, 5.1216e-08, 6.5024e-07, 5.1440e-07, 4.5326e-07,\n",
      "        3.3495e-07, 9.3594e-09, 3.7403e-07, 1.4191e-06, 6.3541e-07, 5.5097e-07,\n",
      "        9.5613e-06, 2.3034e-06, 1.3032e-07, 1.5851e-08, 3.9380e-09, 4.4827e-07,\n",
      "        9.3789e-06, 1.0875e-07, 1.1909e-07, 1.9340e-05, 4.6175e-06, 6.1345e-07,\n",
      "        2.2519e-05, 2.7271e-07, 2.4799e-08, 7.8122e-08, 3.7809e-07, 2.0109e-09,\n",
      "        8.2828e-08, 4.2335e-07, 2.0325e-08, 9.9324e-08, 2.5617e-07, 2.9431e-07,\n",
      "        7.6842e-08, 1.3858e-06, 2.5660e-06, 3.0705e-06, 2.7318e-05, 1.9467e-06,\n",
      "        1.8253e-08, 3.0549e-07, 1.4173e-06, 3.2821e-07, 5.1450e-06, 4.5799e-07,\n",
      "        4.1337e-07, 2.8971e-06, 1.1367e-06, 9.5384e-07, 9.9671e-07, 9.7991e-07,\n",
      "        1.5353e-05, 6.7838e-07, 1.3548e-07, 9.7582e-08, 4.3272e-07, 3.1815e-09,\n",
      "        1.8463e-07, 3.5902e-07, 2.8727e-07, 5.1395e-08, 2.3341e-08, 4.0379e-07,\n",
      "        7.7843e-08, 2.6144e-08, 2.3666e-09, 3.1901e-07, 1.5370e-07, 2.7065e-05,\n",
      "        2.4361e-06, 2.3417e-07, 4.4093e-06, 1.0163e-08, 3.7309e-07, 1.9445e-06,\n",
      "        3.7269e-06, 2.0246e-06, 2.7814e-07, 1.1297e-06, 1.6989e-06, 4.5535e-08,\n",
      "        8.3805e-07, 6.1256e-07, 5.3640e-08, 1.6760e-08, 4.4251e-08, 8.8049e-08,\n",
      "        6.5732e-06, 2.4231e-06, 3.4349e-07, 2.9437e-07, 1.9981e-08, 3.2105e-07,\n",
      "        1.2023e-07, 3.4457e-07, 1.3067e-07, 6.8178e-07, 9.5956e-06, 1.7218e-07,\n",
      "        2.9186e-07, 9.8740e-07, 1.2197e-07, 5.1106e-08, 9.7978e-09, 6.3165e-08,\n",
      "        1.4853e-06, 3.6861e-09, 6.7289e-07, 2.1981e-06, 1.5383e-06, 3.7863e-06,\n",
      "        8.7544e-07, 8.8763e-09, 2.3494e-07, 9.1230e-06, 8.1575e-08, 2.9458e-06,\n",
      "        3.5886e-07, 1.2731e-07, 7.2442e-07, 4.9291e-07, 4.0807e-07, 3.9548e-08,\n",
      "        3.8268e-07, 2.9060e-07, 2.1999e-07, 3.5320e-06, 3.7342e-07, 3.1346e-08,\n",
      "        9.6834e-07, 8.3035e-08, 2.9030e-07, 5.2149e-10, 7.5826e-09, 3.6560e-08,\n",
      "        1.1612e-07, 2.2320e-08, 2.5588e-06, 1.3546e-05])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-12 18:56:41--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt.3’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2022-12-12 18:56:41 (2.94 MB/s) - ‘imagenet_classes.txt.3’ saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.8303046226501465\n",
      "Pomeranian 0.06988755613565445\n",
      "keeshond 0.01296406053006649\n",
      "collie 0.010797739028930664\n",
      "Great Pyrenees 0.009886739775538445\n",
      "Shetland sheepdog 0.008079971186816692\n",
      "Eskimo dog 0.007716516498476267\n",
      "Border collie 0.006666215136647224\n",
      "Siberian husky 0.005079002119600773\n",
      "Arctic fox 0.004981102887541056\n",
      "West Highland white terrier 0.004850371275097132\n",
      "schipperke 0.003958225250244141\n",
      "white wolf 0.003950091544538736\n",
      "malamute 0.00391095457598567\n",
      "Angora 0.0024832526687532663\n",
      "wallaby 0.002022006781771779\n",
      "Pembroke 0.0019301521824672818\n",
      "papillon 0.0014838646166026592\n",
      "groenendael 0.0014537437818944454\n",
      "kuvasz 0.0006565293879248202\n",
      "Persian cat 0.000547415460459888\n",
      "Old English sheepdog 0.0003379475383553654\n",
      "Scotch terrier 0.0003294127818662673\n",
      "hen 0.0002858813968487084\n",
      "Japanese spaniel 0.0002712786372285336\n",
      "hare 0.0002564542228356004\n",
      "Chihuahua 0.00022618153889197856\n",
      "Cardigan 0.00019642522966023535\n",
      "chow 0.00019524042727425694\n",
      "Norwegian elkhound 0.00016818262520246208\n",
      "croquet ball 0.00016535900067538023\n",
      "Pekinese 0.000155609508510679\n",
      "kelpie 0.00015027890913188457\n",
      "Norwich terrier 0.00013577980280388147\n",
      "tennis ball 0.00012405621237121522\n",
      "cairn 0.00011793401063187048\n",
      "broom 0.00011011671449523419\n",
      "llama 0.00010588083387119696\n",
      "barrow 9.95457376120612e-05\n",
      "Newfoundland 9.284508269047365e-05\n",
      "German shepherd 8.021060784813017e-05\n",
      "hamster 7.679925329284742e-05\n",
      "Ibizan hound 7.282845763256773e-05\n",
      "doormat 6.877875421196222e-05\n",
      "plunger 6.692235183436424e-05\n",
      "shovel 6.112025585025549e-05\n",
      "timber wolf 5.898711606278084e-05\n",
      "bucket 5.267016967991367e-05\n",
      "fox squirrel 5.1825365517288446e-05\n",
      "pole 4.848317621508613e-05\n",
      "borzoi 4.819082823814824e-05\n",
      "rain barrel 4.810551035916433e-05\n",
      "dingo 4.810532846022397e-05\n",
      "milk can 4.672944487538189e-05\n",
      "golden retriever 4.6619366912636906e-05\n",
      "Australian terrier 4.407073720358312e-05\n",
      "red fox 4.205716322758235e-05\n",
      "racer 3.9300633943639696e-05\n",
      "Norfolk terrier 3.7864389014430344e-05\n",
      "feather boa 3.7166959373280406e-05\n",
      "Egyptian cat 3.667168130050413e-05\n",
      "barrel 3.4971515560755506e-05\n",
      "paper towel 3.464870314928703e-05\n",
      "lawn mower 3.3918608096428216e-05\n",
      "black-footed ferret 3.06508009089157e-05\n",
      "Maltese dog 2.9584814910776913e-05\n",
      "chainlink fence 2.8544605811475776e-05\n",
      "missile 2.8301381462370045e-05\n",
      "water bottle 2.731804306677077e-05\n",
      "ice lolly 2.70647960860515e-05\n",
      "tabby 2.62670964730205e-05\n",
      "lynx 2.4064949684543535e-05\n",
      "Siamese cat 2.4036462491494603e-05\n",
      "vacuum 2.2518877813126892e-05\n",
      "pinwheel 2.2305035599856637e-05\n",
      "komondor 2.1811354599776678e-05\n",
      "tiger cat 2.097903416142799e-05\n",
      "polecat 2.0939958631061018e-05\n",
      "submarine 2.07689190574456e-05\n",
      "briard 2.0670140656875446e-05\n",
      "remote control 2.04231128009269e-05\n",
      "cock 1.9409044398344122e-05\n",
      "umbrella 1.9339551727171056e-05\n",
      "dhole 1.857900497270748e-05\n",
      "stethoscope 1.8004539015237242e-05\n",
      "Bernese mountain dog 1.7107278836192563e-05\n",
      "projectile 1.7035466953529976e-05\n",
      "wood rabbit 1.6391724784625694e-05\n",
      "ashcan 1.623614298296161e-05\n",
      "worm fence 1.5352879927377217e-05\n",
      "weasel 1.534834154881537e-05\n",
      "Irish wolfhound 1.4584135897166561e-05\n",
      "grey fox 1.4540250958816614e-05\n",
      "quill 1.4515685506921727e-05\n",
      "soccer ball 1.4197414202499203e-05\n",
      "guinea pig 1.4060461580811534e-05\n",
      "wire-haired fox terrier 1.3856923942512367e-05\n",
      "toilet tissue 1.3545768524636514e-05\n",
      "Saint Bernard 1.26974809973035e-05\n",
      "clog 1.0830332939804066e-05\n",
      "racket 1.0771218512672931e-05\n",
      "mousetrap 1.0228880455542821e-05\n",
      "English setter 9.803453394852113e-06\n",
      "hay 9.595628398528788e-06\n",
      "revolver 9.589480214344803e-06\n",
      "tricycle 9.561299521010369e-06\n",
      "skunk 9.456380212213844e-06\n",
      "tub 9.378943104820792e-06\n",
      "lakeside 9.12298582989024e-06\n",
      "bow tie 8.900576176529285e-06\n",
      "picket fence 8.86443922354374e-06\n",
      "space heater 8.588333912484813e-06\n",
      "beer bottle 8.471140972687863e-06\n",
      "kit fox 8.445683306490537e-06\n",
      "Brittany spaniel 8.02180602477165e-06\n",
      "muzzle 7.68466907175025e-06\n",
      "bow 7.470118362107314e-06\n",
      "candle 7.312377874768572e-06\n",
      "basenji 6.9190491558401845e-06\n",
      "maze 6.88989894115366e-06\n",
      "sulphur-crested cockatoo 6.620695785386488e-06\n",
      "Granny Smith 6.573208793270169e-06\n",
      "sports car 6.572575784957735e-06\n",
      "binoculars 6.533691248478135e-06\n",
      "punching bag 6.489186034741579e-06\n",
      "crate 6.4450077843503095e-06\n",
      "carton 6.434444458136568e-06\n",
      "golf ball 6.229457994777476e-06\n",
      "reel 6.212596872501308e-06\n",
      "Appenzeller 6.167825176817132e-06\n",
      "Irish terrier 6.064643457648344e-06\n",
      "swab 5.9087078625452705e-06\n",
      "ram 5.864587819814915e-06\n",
      "Tibetan terrier 5.7059705795836635e-06\n",
      "hog 5.44000386071275e-06\n",
      "Scottish deerhound 5.426677034847671e-06\n",
      "rifle 5.330589374352712e-06\n",
      "plastic bag 5.326711743691703e-06\n",
      "Bouvier des Flandres 5.284064627630869e-06\n",
      "breakwater 5.228907411947148e-06\n",
      "window screen 5.144994247530121e-06\n",
      "malinois 5.107204742671456e-06\n",
      "dogsled 5.0757698772940785e-06\n",
      "Sealyham terrier 5.049456831329735e-06\n",
      "go-kart 4.962565526511753e-06\n",
      "radio 4.937780886393739e-06\n",
      "coyote 4.832536887988681e-06\n",
      "flagpole 4.8078059080580715e-06\n",
      "bobsled 4.735994934890186e-06\n",
      "marmoset 4.730086402560119e-06\n",
      "cowboy hat 4.672255727200536e-06\n",
      "spotlight 4.633615844795713e-06\n",
      "unicycle 4.617540525941877e-06\n",
      "flute 4.571232693706406e-06\n",
      "sleeping bag 4.569973043544451e-06\n",
      "switch 4.541385351330973e-06\n",
      "baseball 4.539298060990404e-06\n",
      "pretzel 4.409295343066333e-06\n",
      "ping-pong ball 4.348517904873006e-06\n",
      "Labrador retriever 4.313776571507333e-06\n",
      "catamaran 4.3038367039116565e-06\n",
      "car wheel 4.300090949982405e-06\n",
      "cocktail shaker 4.267213171260664e-06\n",
      "drumstick 4.184749741398264e-06\n",
      "hatchet 4.106400865566684e-06\n",
      "tench 3.9431938603229355e-06\n",
      "lipstick 3.897294845955912e-06\n",
      "chain 3.8681059777445626e-06\n",
      "standard poodle 3.865332473651506e-06\n",
      "Dutch oven 3.820949132204987e-06\n",
      "English springer 3.7991294448147528e-06\n",
      "padlock 3.7873473957006354e-06\n",
      "bubble 3.7863035231566755e-06\n",
      "mailbag 3.7678896660509054e-06\n",
      "caldron 3.7453730783454375e-06\n",
      "cannon 3.7377403714344837e-06\n",
      "head cabbage 3.72690919903107e-06\n",
      "corn 3.5319501421327004e-06\n",
      "canoe 3.529539299051976e-06\n",
      "manhole cover 3.4835686619771877e-06\n",
      "clumber 3.4595493616507156e-06\n",
      "Sussex spaniel 3.3941855690500233e-06\n",
      "quilt 3.390310212125769e-06\n",
      "American Staffordshire terrier 3.3434125725761987e-06\n",
      "printer 3.2367258882004535e-06\n",
      "paintbrush 3.1835472782404395e-06\n",
      "stretcher 3.1499134820478503e-06\n",
      "radiator 3.142457444482716e-06\n",
      "limousine 3.134905227852869e-06\n",
      "washer 3.07049981529417e-06\n",
      "lotion 3.0484154649457196e-06\n",
      "porcupine 3.0089981919445563e-06\n",
      "computer keyboard 2.9935879410913913e-06\n",
      "rocking chair 2.976129735543509e-06\n",
      "piggy bank 2.9756954518234124e-06\n",
      "sandbar 2.9457742130034603e-06\n",
      "sunglasses 2.9069908578094328e-06\n",
      "wine bottle 2.8971023766644066e-06\n",
      "syringe 2.8613192171178525e-06\n",
      "screen 2.7977941954304697e-06\n",
      "acoustic guitar 2.7060575575887924e-06\n",
      "television 2.696230012588785e-06\n",
      "red wolf 2.679583531062235e-06\n",
      "crutch 2.621818111947505e-06\n",
      "cocker spaniel 2.6163904749409994e-06\n",
      "park bench 2.6142031401832355e-06\n",
      "washbasin 2.5659928724053316e-06\n",
      "military uniform 2.5623639885452576e-06\n",
      "ear 2.5587987693143077e-06\n",
      "hoopskirt 2.5523816020722734e-06\n",
      "jean 2.537377895350801e-06\n",
      "Lhasa 2.497708464943571e-06\n",
      "monitor 2.479046315784217e-06\n",
      "electric fan 2.4617866074549966e-06\n",
      "French loaf 2.4361359010072192e-06\n",
      "strawberry 2.4231185307144187e-06\n",
      "axolotl 2.366517492191633e-06\n",
      "toy terrier 2.3392035473079886e-06\n",
      "beach wagon 2.3351421987172216e-06\n",
      "wombat 2.3326563223236008e-06\n",
      "trimaran 2.3033942397887586e-06\n",
      "dishwasher 2.2990798242972232e-06\n",
      "French horn 2.291304781465442e-06\n",
      "otterhound 2.2782510313845705e-06\n",
      "miniature pinscher 2.268321395604289e-06\n",
      "stone wall 2.218812596765929e-06\n",
      "titi 2.2063945834815968e-06\n",
      "eggnog 2.1980777091812342e-06\n",
      "shield 2.1901932996115647e-06\n",
      "panpipe 2.1607290818792535e-06\n",
      "EntleBucher 2.145002099496196e-06\n",
      "golfcart 2.120491444657091e-06\n",
      "joystick 2.099739958794089e-06\n",
      "tiger 2.098777031278587e-06\n",
      "macaque 2.0718837276945123e-06\n",
      "sundial 2.067722789433901e-06\n",
      "packet 2.052060153800994e-06\n",
      "amphibian 2.04841580853099e-06\n",
      "mailbox 2.030940322583774e-06\n",
      "broccoli 2.024554532908951e-06\n",
      "bicycle-built-for-two 2.0012162167404313e-06\n",
      "snow leopard 1.9878025341313332e-06\n",
      "dalmatian 1.973494136109366e-06\n",
      "Shih-Tzu 1.955396783159813e-06\n",
      "cloak 1.9484998574625934e-06\n",
      "water jug 1.9466572211968014e-06\n",
      "mashed potato 1.944536734299618e-06\n",
      "rugby ball 1.9299836822028738e-06\n",
      "stove 1.9226299627916887e-06\n",
      "hammer 1.917554072861094e-06\n",
      "convertible 1.9136498394800583e-06\n",
      "shopping cart 1.910650325953611e-06\n",
      "hair slide 1.8629864371177973e-06\n",
      "night snake 1.8563163166618324e-06\n",
      "gar 1.8119835658580996e-06\n",
      "flat-coated retriever 1.8096038729709107e-06\n",
      "mobile home 1.8007638118433533e-06\n",
      "sunscreen 1.7912423118104925e-06\n",
      "chain saw 1.7844292869995115e-06\n",
      "centipede 1.7796060092223343e-06\n",
      "Border terrier 1.7682275483821286e-06\n",
      "Staffordshire bullterrier 1.7667038036961458e-06\n",
      "grille 1.7548001096656662e-06\n",
      "Greater Swiss Mountain dog 1.7506495169072878e-06\n",
      "common iguana 1.7423998315280187e-06\n",
      "bathtub 1.7399455600752844e-06\n",
      "indri 1.704618284747994e-06\n",
      "patas 1.699970539448259e-06\n",
      "spaghetti squash 1.69889767676068e-06\n",
      "miniskirt 1.6841726164784632e-06\n",
      "knee pad 1.6785812704256386e-06\n",
      "strainer 1.6531656683582696e-06\n",
      "Christmas stocking 1.638848061702447e-06\n",
      "pier 1.6237111140071647e-06\n",
      "minivan 1.606402179277211e-06\n",
      "lens cap 1.6035689895943506e-06\n",
      "maraca 1.5990807469279389e-06\n",
      "stole 1.5964841395543772e-06\n",
      "beacon 1.5958737549226498e-06\n",
      "odometer 1.5928600305414875e-06\n",
      "shower cap 1.590090164427238e-06\n",
      "bassinet 1.576183535689779e-06\n",
      "refrigerator 1.5537343642790802e-06\n",
      "alp 1.538268179501756e-06\n",
      "Boston bull 1.526253640804498e-06\n",
      "stopwatch 1.515732947154902e-06\n",
      "liner 1.495888454883243e-06\n",
      "red wine 1.4852512322249822e-06\n",
      "giant schnauzer 1.4786949122935766e-06\n",
      "Leonberg 1.4782747257413575e-06\n",
      "tank 1.4765754485779325e-06\n",
      "harp 1.4647409898316255e-06\n",
      "trailer truck 1.419084128428949e-06\n",
      "whistle 1.417254225088982e-06\n",
      "prairie chicken 1.401079430252139e-06\n",
      "crayfish 1.3973617569718044e-06\n",
      "apron 1.3860087619832484e-06\n",
      "warplane 1.385836981171451e-06\n",
      "mouse 1.3750209291174542e-06\n",
      "mink 1.3639703411172377e-06\n",
      "hamper 1.358326358058548e-06\n",
      "half track 1.351961373075028e-06\n",
      "cinema 1.3482018630384118e-06\n",
      "pillow 1.3166480812287773e-06\n",
      "electric ray 1.2818450159102213e-06\n",
      "holster 1.280686547033838e-06\n",
      "Madagascar cat 1.2727638249998563e-06\n",
      "Loafer 1.253571667803044e-06\n",
      "langur 1.2514311720224214e-06\n",
      "thimble 1.2458333458198467e-06\n",
      "laptop 1.2368114994387724e-06\n",
      "sunglass 1.2233700772412703e-06\n",
      "gown 1.1968534181505674e-06\n",
      "Tibetan mastiff 1.1562924555619247e-06\n",
      "shopping basket 1.1454486639195238e-06\n",
      "hyena 1.144195266533643e-06\n",
      "teapot 1.1376029078746797e-06\n",
      "wing 1.1366864782758057e-06\n",
      "folding chair 1.1318759334244533e-06\n",
      "zucchini 1.1297041737634572e-06\n",
      "marmot 1.1264722843407071e-06\n",
      "coffeepot 1.1138147328892956e-06\n",
      "green lizard 1.1088028486483381e-06\n",
      "gong 1.1058829159082961e-06\n",
      "cornet 1.1055485629185569e-06\n",
      "American egret 1.0886452628255938e-06\n",
      "armadillo 1.0868133131225477e-06\n",
      "binder 1.0822068361449055e-06\n",
      "snowplow 1.0685117786124465e-06\n",
      "pickup 1.0555799008216127e-06\n",
      "plow 1.0536680292716483e-06\n",
      "screw 1.0514827408769634e-06\n",
      "Welsh springer spaniel 1.0454155017214362e-06\n",
      "dumbbell 1.0405029797766474e-06\n",
      "breastplate 1.0356776556363911e-06\n",
      "lesser panda 1.0181157676925068e-06\n",
      "frying pan 9.998120731324889e-07\n",
      "wooden spoon 9.96713197309873e-07\n",
      "castle 9.931038675858872e-07\n",
      "dough 9.874027000478236e-07\n",
      "wool 9.799064173421357e-07\n",
      "peacock 9.747326430442627e-07\n",
      "buckeye 9.683433290774701e-07\n",
      "toy poodle 9.586768783265143e-07\n",
      "nipple 9.540135579300113e-07\n",
      "wok 9.53838934947271e-07\n",
      "spatula 9.503523301646055e-07\n",
      "mountain bike 9.454995506530395e-07\n",
      "chime 9.426841529602825e-07\n",
      "slug 9.350092113891151e-07\n",
      "cab 9.332319450550131e-07\n",
      "hair spray 9.306332344749535e-07\n",
      "combination lock 9.252871109310945e-07\n",
      "barn 9.24089533782535e-07\n",
      "assault rifle 9.239856240128574e-07\n",
      "black swan 9.20496574963181e-07\n",
      "pay-phone 9.132687637247727e-07\n",
      "coil 9.130823741543281e-07\n",
      "rotisserie 9.072520015251939e-07\n",
      "nail 9.060501611202199e-07\n",
      "fountain pen 9.052624250216468e-07\n",
      "carpenter's kit 8.967873554865946e-07\n",
      "ruffed grouse 8.907026085580583e-07\n",
      "knot 8.831459012981213e-07\n",
      "vizsla 8.823865300655598e-07\n",
      "cliff 8.754429359214555e-07\n",
      "bonnet 8.718053550182958e-07\n",
      "grand piano 8.706621201781672e-07\n",
      "mortarboard 8.623678695585113e-07\n",
      "Doberman 8.610637109995878e-07\n",
      "pitcher 8.595916938247683e-07\n",
      "studio couch 8.5154505313767e-07\n",
      "butternut squash 8.38051334994816e-07\n",
      "snowmobile 8.314447086377186e-07\n",
      "matchstick 8.31034128623287e-07\n",
      "hand-held computer 8.169493526111182e-07\n",
      "beagle 7.980140708241379e-07\n",
      "American alligator 7.897774594312068e-07\n",
      "silky terrier 7.886086450525909e-07\n",
      "paddle 7.858271828808938e-07\n",
      "purse 7.833377821953036e-07\n",
      "sombrero 7.821217309356143e-07\n",
      "hand blower 7.804489996487973e-07\n",
      "cellular telephone 7.800665571267018e-07\n",
      "sarong 7.750301165287965e-07\n",
      "running shoe 7.644142101526086e-07\n",
      "speedboat 7.388741209979344e-07\n",
      "miniature poodle 7.361163625319023e-07\n",
      "albatross 7.323561703742598e-07\n",
      "eft 7.31303714474052e-07\n",
      "volcano 7.244150879159861e-07\n",
      "scabbard 7.033046358628781e-07\n",
      "coho 7.007030262684566e-07\n",
      "stupa 6.898659421494813e-07\n",
      "pomegranate 6.817800226599502e-07\n",
      "wreck 6.783828325751529e-07\n",
      "Band Aid 6.772980896130321e-07\n",
      "suspension bridge 6.751196792720293e-07\n",
      "Blenheim spaniel 6.741867082382669e-07\n",
      "cup 6.728872676831088e-07\n",
      "microphone 6.68991219754389e-07\n",
      "sock 6.610225682379678e-07\n",
      "oboe 6.567829586856533e-07\n",
      "sliding door 6.507495413643483e-07\n",
      "toilet seat 6.50238348498533e-07\n",
      "poncho 6.500064841929998e-07\n",
      "CD player 6.486151278295438e-07\n",
      "beer glass 6.455733227994642e-07\n",
      "Kerry blue terrier 6.448041744988586e-07\n",
      "bullfrog 6.386341624420311e-07\n",
      "tray 6.354052288770617e-07\n",
      "file 6.341079483718204e-07\n",
      "Dandie Dinmont 6.333344231279625e-07\n",
      "digital clock 6.308532078946882e-07\n",
      "loudspeaker 6.236278409232909e-07\n",
      "upright 6.134530963208817e-07\n",
      "cucumber 6.125616209828877e-07\n",
      "rule 6.118831379353651e-07\n",
      "barbell 6.070710583117034e-07\n",
      "dishrag 6.06510923262249e-07\n",
      "Chesapeake Bay retriever 6.036274271536968e-07\n",
      "accordion 6.035405704096775e-07\n",
      "ox 5.929551321059989e-07\n",
      "fountain 5.918568604101893e-07\n",
      "banjo 5.912503979743633e-07\n",
      "curly-coated retriever 5.90820889101451e-07\n",
      "iron 5.86793021284393e-07\n",
      "loupe 5.827465088259487e-07\n",
      "redbone 5.69247731618816e-07\n",
      "leopard 5.669836014021712e-07\n",
      "horned viper 5.662886906065978e-07\n",
      "greenhouse 5.56992631572939e-07\n",
      "goose 5.52287644950411e-07\n",
      "cradle 5.519759156413784e-07\n",
      "trench coat 5.50966149148735e-07\n",
      "sweatshirt 5.476736646414793e-07\n",
      "parking meter 5.448251272355265e-07\n",
      "affenpinscher 5.412651944425306e-07\n",
      "bath towel 5.389699140323501e-07\n",
      "notebook 5.359549959393917e-07\n",
      "ice bear 5.310427013682784e-07\n",
      "corkscrew 5.305359991325531e-07\n",
      "goblet 5.273238343761477e-07\n",
      "Italian greyhound 5.197691734792897e-07\n",
      "analog clock 5.191613468014111e-07\n",
      "American lobster 5.186971065995749e-07\n",
      "standard schnauzer 5.157921805221122e-07\n",
      "Dungeness crab 5.157528448762605e-07\n",
      "torch 5.144039505466935e-07\n",
      "power drill 5.094384505355265e-07\n",
      "parachute 5.073884494777303e-07\n",
      "bassoon 5.067443566986185e-07\n",
      "garbage truck 5.060836087977805e-07\n",
      "walking stick 5.027025054005207e-07\n",
      "Afghan hound 5.010216455048067e-07\n",
      "ambulance 4.975011052010814e-07\n",
      "spiny lobster 4.96839675179217e-07\n",
      "steel drum 4.962188882018381e-07\n",
      "ballplayer 4.929121928398672e-07\n",
      "seat belt 4.919888283438922e-07\n",
      "coffee mug 4.900375643046573e-07\n",
      "hook 4.835351319343317e-07\n",
      "mitten 4.802574835593987e-07\n",
      "forklift 4.78740219023166e-07\n",
      "Rhodesian ridgeback 4.784380394085019e-07\n",
      "cleaver 4.778675588568149e-07\n",
      "beaver 4.746193269511423e-07\n",
      "oscilloscope 4.7281176307478745e-07\n",
      "slot 4.72109320526215e-07\n",
      "Petri dish 4.68172316914206e-07\n",
      "barometer 4.679205574120715e-07\n",
      "rock crab 4.6447360091406154e-07\n",
      "shower curtain 4.596265057443816e-07\n",
      "window shade 4.579905237278581e-07\n",
      "gas pump 4.5535864501289325e-07\n",
      "totem pole 4.5326123654376715e-07\n",
      "pedestal 4.5162849460211874e-07\n",
      "barracouta 4.5022014205642336e-07\n",
      "trombone 4.4827078227172024e-07\n",
      "screwdriver 4.475416233162832e-07\n",
      "African crocodile 4.438835503606242e-07\n",
      "bannister 4.4235162022232544e-07\n",
      "sandal 4.4059598280909995e-07\n",
      "lighter 4.394671577756526e-07\n",
      "sorrel 4.3670263494277606e-07\n",
      "web site 4.327177975937957e-07\n",
      "pencil box 4.312462351663271e-07\n",
      "mosquito net 4.31164806968809e-07\n",
      "electric guitar 4.2841372760449303e-07\n",
      "miniature schnauzer 4.268574400612124e-07\n",
      "disk brake 4.267654674094956e-07\n",
      "buckle 4.243377702550788e-07\n",
      "violin 4.233498884786968e-07\n",
      "mongoose 4.168909697455092e-07\n",
      "spider web 4.1611363599258766e-07\n",
      "Windsor tie 4.133714526233234e-07\n",
      "jersey 4.1310701703878294e-07\n",
      "crash helmet 4.1259633576373744e-07\n",
      "groom 4.0807265122566605e-07\n",
      "steel arch bridge 4.0484644614480203e-07\n",
      "crane 4.040803673888149e-07\n",
      "plate 4.037860890093725e-07\n",
      "cuirass 3.9409738405993266e-07\n",
      "koala 3.9280399732888327e-07\n",
      "maillot 3.8502025745401625e-07\n",
      "rapeseed 3.8267631907729083e-07\n",
      "spindle 3.805527910571982e-07\n",
      "letter opener 3.8022483295208076e-07\n",
      "chain mail 3.7998376001269207e-07\n",
      "bakery 3.7970087873873126e-07\n",
      "vending machine 3.780885720061633e-07\n",
      "brass 3.757994022635103e-07\n",
      "fire engine 3.7557222754003305e-07\n",
      "tractor 3.7403131614155427e-07\n",
      "puck 3.7399351526801183e-07\n",
      "acorn 3.7341578718042e-07\n",
      "hotdog 3.73090102812057e-07\n",
      "badger 3.7123632523616834e-07\n",
      "pot 3.6963774618925527e-07\n",
      "Lakeland terrier 3.682472424770822e-07\n",
      "planetarium 3.6451211826715735e-07\n",
      "paddlewheel 3.6362155242386507e-07\n",
      "tailed frog 3.5951103427578346e-07\n",
      "street sign 3.5902007766708266e-07\n",
      "seashore 3.5885918236999714e-07\n",
      "cougar 3.5776741924564703e-07\n",
      "envelope 3.5574404932958714e-07\n",
      "recreational vehicle 3.5478558402246563e-07\n",
      "moving van 3.5425409805611707e-07\n",
      "soft-coated wheaten terrier 3.472395633252745e-07\n",
      "banded gecko 3.455152466358413e-07\n",
      "guenon 3.4516415325924754e-07\n",
      "jackfruit 3.4457346487215545e-07\n",
      "chiffonier 3.4419019812048646e-07\n",
      "orange 3.434930420098681e-07\n",
      "tick 3.4339413446105027e-07\n",
      "Brabancon griffon 3.3975942415054305e-07\n",
      "Model T 3.396492616047908e-07\n",
      "fireboat 3.390340737041697e-07\n",
      "king crab 3.3895193496391585e-07\n",
      "jay 3.383144644431013e-07\n",
      "tow truck 3.3494586659799097e-07\n",
      "schooner 3.338494423132943e-07\n",
      "spider monkey 3.297058412954357e-07\n",
      "lab coat 3.288485572738864e-07\n",
      "wig 3.2821472473187896e-07\n",
      "squirrel monkey 3.220359303668374e-07\n",
      "Great Dane 3.219582538349641e-07\n",
      "pop bottle 3.2110824577102903e-07\n",
      "pineapple 3.210500949535344e-07\n",
      "grasshopper 3.208838847967854e-07\n",
      "trifle 3.1900859198685794e-07\n",
      "gazelle 3.17988025244631e-07\n",
      "reflex camera 3.148302027966565e-07\n",
      "alligator lizard 3.105155030880269e-07\n",
      "sax 3.100671790434717e-07\n",
      "pajama 3.08963819861674e-07\n",
      "kimono 3.0799151318205986e-07\n",
      "mortar 3.06409788208839e-07\n",
      "diaper 3.0558132380065217e-07\n",
      "whiskey jug 3.0549185225936526e-07\n",
      "maypole 3.0520618565788027e-07\n",
      "soap dispenser 3.0157420383147837e-07\n",
      "solar dish 3.0037352871659095e-07\n",
      "snail 2.988913649915048e-07\n",
      "motor scooter 2.950704356408096e-07\n",
      "lemon 2.9437200055326684e-07\n",
      "wallet 2.943108086128632e-07\n",
      "fire screen 2.941197294603626e-07\n",
      "Rottweiler 2.9245745736261597e-07\n",
      "chocolate sauce 2.918639836479997e-07\n",
      "chest 2.916967503097112e-07\n",
      "desktop computer 2.9082593755447306e-07\n",
      "daisy 2.9060137762826344e-07\n",
      "agaric 2.902955884565017e-07\n",
      "wild boar 2.896181001688092e-07\n",
      "jeep 2.8853659728156344e-07\n",
      "safe 2.8747390956596064e-07\n",
      "traffic light 2.872658910746395e-07\n",
      "iPod 2.8508989657893835e-07\n",
      "dial telephone 2.849586167030793e-07\n",
      "hognose snake 2.824524187872157e-07\n",
      "microwave 2.810069190672948e-07\n",
      "Irish setter 2.8080066272195836e-07\n",
      "cauliflower 2.781418402264535e-07\n",
      "Mexican hairless 2.7651159939523495e-07\n",
      "terrapin 2.7500917099132494e-07\n",
      "tape player 2.7467339691611414e-07\n",
      "vase 2.727147432324273e-07\n",
      "scoreboard 2.7130511170980753e-07\n",
      "pick 2.703432642192638e-07\n",
      "projector 2.6989144430444867e-07\n",
      "French bulldog 2.6963752475239744e-07\n",
      "bell cote 2.678153805391048e-07\n",
      "palace 2.6604061531543266e-07\n",
      "echidna 2.638575153923739e-07\n",
      "water snake 2.632359610288404e-07\n",
      "Yorkshire terrier 2.619992187646858e-07\n",
      "modem 2.6140597242374497e-07\n",
      "cash machine 2.608635440992657e-07\n",
      "sea cucumber 2.594416912415909e-07\n",
      "tree frog 2.586733671705588e-07\n",
      "mountain tent 2.5854856744444987e-07\n",
      "safety pin 2.5638587430876214e-07\n",
      "wall clock 2.5616833454478183e-07\n",
      "Walker hound 2.538695582643413e-07\n",
      "Komodo dragon 2.5006315240716503e-07\n",
      "overskirt 2.483062644387246e-07\n",
      "magnetic compass 2.478260228144791e-07\n",
      "mask 2.4760350925134844e-07\n",
      "otter 2.448152258693881e-07\n",
      "capuchin 2.4375128759857034e-07\n",
      "ski 2.423119553895958e-07\n",
      "ptarmigan 2.4133436227202765e-07\n",
      "carousel 2.385461641551956e-07\n",
      "cricket 2.3553015182642412e-07\n",
      "geyser 2.349448635641238e-07\n",
      "bagel 2.3417376837642223e-07\n",
      "ant 2.3348249555965594e-07\n",
      "sidewinder 2.2964816537296429e-07\n",
      "drum 2.2961862100601138e-07\n",
      "basset 2.2954196765567758e-07\n",
      "suit 2.2713790315265214e-07\n",
      "meerkat 2.2699066448694794e-07\n",
      "boathouse 2.23595151283007e-07\n",
      "thunder snake 2.2199520799404127e-07\n",
      "yellow lady's slipper 2.199890616338962e-07\n",
      "Irish water spaniel 2.1944362060821732e-07\n",
      "rhinoceros beetle 2.191029722098392e-07\n",
      "bulletproof vest 2.172095321384404e-07\n",
      "jack-o'-lantern 2.160668230999363e-07\n",
      "maillot 2.156184848445264e-07\n",
      "boxer 2.1465420729782636e-07\n",
      "partridge 2.1037094199982675e-07\n",
      "bearskin 2.0779161502559873e-07\n",
      "cassette player 2.052853886880257e-07\n",
      "marimba 2.0279006207601924e-07\n",
      "handkerchief 2.0021504099076992e-07\n",
      "howler monkey 1.9945120754982781e-07\n",
      "gibbon 1.9935573902785109e-07\n",
      "baboon 1.976964796313041e-07\n",
      "jigsaw puzzle 1.9733894873752433e-07\n",
      "African hunting dog 1.966297844546716e-07\n",
      "bookcase 1.9508638615661766e-07\n",
      "teddy 1.9201516465727764e-07\n",
      "bib 1.905065403207118e-07\n",
      "balloon 1.8873255669404898e-07\n",
      "scorpion 1.8748772845356143e-07\n",
      "football helmet 1.86003134672319e-07\n",
      "barber chair 1.8472100293820404e-07\n",
      "crossword puzzle 1.846332793320471e-07\n",
      "home theater 1.7657275463989208e-07\n",
      "airship 1.7620888570490933e-07\n",
      "spoonbill 1.7556176601374318e-07\n",
      "moped 1.744934934322373e-07\n",
      "dam 1.743276527577109e-07\n",
      "abacus 1.7414122055470216e-07\n",
      "cockroach 1.7377591632339318e-07\n",
      "table lamp 1.7364652649121126e-07\n",
      "fur coat 1.7303783295119501e-07\n",
      "ballpoint 1.728755449903474e-07\n",
      "gasmask 1.7230505022780562e-07\n",
      "carbonara 1.7218316372691334e-07\n",
      "sulphur butterfly 1.7029682908287214e-07\n",
      "theater curtain 1.6923362977649958e-07\n",
      "obelisk 1.6593124030350737e-07\n",
      "bikini 1.63240358119765e-07\n",
      "lifeboat 1.6185728668460797e-07\n",
      "ringneck snake 1.6037087391396199e-07\n",
      "brassiere 1.5957024857016222e-07\n",
      "sea slug 1.588922202699905e-07\n",
      "thresher 1.5716827306277992e-07\n",
      "white stork 1.569757728248078e-07\n",
      "mixing bowl 1.5593090552101785e-07\n",
      "thatch 1.548473278489837e-07\n",
      "king penguin 1.5413395715313527e-07\n",
      "prayer rug 1.5399922403958044e-07\n",
      "china cabinet 1.539749803214363e-07\n",
      "ice cream 1.5369960237876512e-07\n",
      "plate rack 1.51364631051365e-07\n",
      "pelican 1.503195363738996e-07\n",
      "harmonica 1.4837115713817184e-07\n",
      "space bar 1.4809280912686518e-07\n",
      "ibex 1.4776044565678603e-07\n",
      "common newt 1.4576669116195262e-07\n",
      "pill bottle 1.4358919031565165e-07\n",
      "lion 1.4355359212459007e-07\n",
      "crib 1.394018909195438e-07\n",
      "grocery store 1.3939975929133652e-07\n",
      "American chameleon 1.3845179580584954e-07\n",
      "Gila monster 1.3701324519388436e-07\n",
      "airliner 1.368189401773634e-07\n",
      "African grey 1.3575964885603753e-07\n",
      "birdhouse 1.3560683953528496e-07\n",
      "yawl 1.3548481092584552e-07\n",
      "lumbermill 1.3441405144476448e-07\n",
      "magpie 1.3440288171295833e-07\n",
      "Crock Pot 1.3370207341267815e-07\n",
      "ostrich 1.328413645751425e-07\n",
      "Gordon setter 1.3212373062287952e-07\n",
      "vulture 1.3167830559268623e-07\n",
      "measuring cup 1.315805064905362e-07\n",
      "sea anemone 1.3075278104679455e-07\n",
      "custard apple 1.3067113968645572e-07\n",
      "tripod 1.303213110759316e-07\n",
      "megalith 1.298670895266696e-07\n",
      "stage 1.294071836355215e-07\n",
      "oxcart 1.293426663551145e-07\n",
      "American black bear 1.2848673236476316e-07\n",
      "giant panda 1.2746312449962716e-07\n",
      "valley 1.2731103993246506e-07\n",
      "Airedale 1.2701985951935058e-07\n",
      "water buffalo 1.2217850553497556e-07\n",
      "meat loaf 1.2197487819776143e-07\n",
      "photocopier 1.2071097899024608e-07\n",
      "banana 1.2023177475839475e-07\n",
      "typewriter keyboard 1.1908934993698495e-07\n",
      "pug 1.1671814803548841e-07\n",
      "European fire salamander 1.1655841802848954e-07\n",
      "hen-of-the-woods 1.161233740276657e-07\n",
      "can opener 1.1510075381693241e-07\n",
      "backpack 1.1458938331543322e-07\n",
      "patio 1.1280530998192262e-07\n",
      "cheetah 1.1262289234537093e-07\n",
      "steam locomotive 1.1256867082920508e-07\n",
      "toucan 1.1226345009163197e-07\n",
      "rock python 1.1052422621560254e-07\n",
      "bolo tie 1.0975735165175138e-07\n",
      "turnstile 1.0875157840928296e-07\n",
      "hard disc 1.0840737729722605e-07\n",
      "tile roof 1.0797979399512769e-07\n",
      "bottlecap 1.0795950800002174e-07\n",
      "cowboy boot 1.0666013139370989e-07\n",
      "weevil 1.062676133756213e-07\n",
      "leatherback turtle 1.0323952892576926e-07\n",
      "bloodhound 1.0301185682237701e-07\n",
      "oxygen mask 1.0300311714672716e-07\n",
      "whippet 1.0219120127885617e-07\n",
      "brown bear 1.0031141783883868e-07\n",
      "lampshade 9.977502912761338e-08\n",
      "waffle iron 9.932378475241421e-08\n",
      "yurt 9.758185370856154e-08\n",
      "stingray 9.724045213488353e-08\n",
      "spotted salamander 9.681139090389479e-08\n",
      "school bus 9.624633889870893e-08\n",
      "car mirror 9.551101243232551e-08\n",
      "snorkel 9.421282953780974e-08\n",
      "church 9.317668769881493e-08\n",
      "medicine chest 9.256538646695844e-08\n",
      "honeycomb 9.225921360211942e-08\n",
      "face powder 9.22125948932262e-08\n",
      "lacewing 9.080877561018497e-08\n",
      "dugong 9.062104311396979e-08\n",
      "vine snake 9.018427959972541e-08\n",
      "long-horned beetle 8.99964689438093e-08\n",
      "three-toed sloth 8.836054377070468e-08\n",
      "mushroom 8.804897078107388e-08\n",
      "triceratops 8.675650775558097e-08\n",
      "goldfish 8.539778661997843e-08\n",
      "ladle 8.47831742589733e-08\n",
      "ocarina 8.347270608055624e-08\n",
      "coral fungus 8.303475595994314e-08\n",
      "viaduct 8.282786012614451e-08\n",
      "barbershop 8.26588362201619e-08\n",
      "radio telescope 8.19664762730099e-08\n",
      "promontory 8.157531539154661e-08\n",
      "neck brace 8.018035657642031e-08\n",
      "black grouse 7.935710044648658e-08\n",
      "dock 7.895428666415683e-08\n",
      "scale 7.862487905185844e-08\n",
      "velvet 7.812215585545346e-08\n",
      "guacamole 7.784282729517145e-08\n",
      "pirate 7.688957737173041e-08\n",
      "wardrobe 7.6842219698392e-08\n",
      "sturgeon 7.498918819237588e-08\n",
      "Polaroid camera 7.439540183895588e-08\n",
      "perfume 7.419036052169758e-08\n",
      "flatworm 7.241633426247063e-08\n",
      "starfish 7.191817985585658e-08\n",
      "swing 7.087102460445749e-08\n",
      "king snake 7.006072166859667e-08\n",
      "abaya 6.93133230811327e-08\n",
      "cassette 6.840996036316938e-08\n",
      "bulbul 6.833067800471326e-08\n",
      "shoe shop 6.825251830377965e-08\n",
      "swimming trunks 6.658008544491167e-08\n",
      "leafhopper 6.60438104205241e-08\n",
      "diamondback 6.602328284088799e-08\n",
      "chiton 6.601257496186008e-08\n",
      "anemone fish 6.596097534838918e-08\n",
      "burrito 6.316505363201941e-08\n",
      "organ 6.296573928921134e-08\n",
      "eel 6.279172026779634e-08\n",
      "African chameleon 6.270637697980419e-08\n",
      "orangutan 6.265461394150407e-08\n",
      "Saluki 6.265401708560603e-08\n",
      "jaguar 6.230984439525855e-08\n",
      "cardigan 6.227823945437194e-08\n",
      "colobus 6.226315463209176e-08\n",
      "necklace 6.14663306919283e-08\n",
      "four-poster 6.090557036486643e-08\n",
      "soup bowl 5.7222148797109185e-08\n",
      "black and gold garden spider 5.7097423677987535e-08\n",
      "gondola 5.706454331289024e-08\n",
      "quail 5.69510270054252e-08\n",
      "shoji 5.6619061439278084e-08\n",
      "horizontal bar 5.629987498423361e-08\n",
      "grey whale 5.5319404168585606e-08\n",
      "passenger car 5.4164235763209945e-08\n",
      "entertainment center 5.394761259935876e-08\n",
      "artichoke 5.36404236584076e-08\n",
      "great white shark 5.1759638353132686e-08\n",
      "book jacket 5.139525782738019e-08\n",
      "frilled lizard 5.128656255237729e-08\n",
      "tobacco shop 5.12156894671989e-08\n",
      "pizza 5.110629786031495e-08\n",
      "English foxhound 5.1061476824543206e-08\n",
      "harvester 5.084853427206326e-08\n",
      "isopod 4.968266509308705e-08\n",
      "bluetick 4.9273189972609543e-08\n",
      "killer whale 4.908296347139185e-08\n",
      "saltshaker 4.80198139030108e-08\n",
      "ground beetle 4.735909087116852e-08\n",
      "sea urchin 4.644228468464462e-08\n",
      "minibus 4.582196311275766e-08\n",
      "acorn squash 4.553463028855731e-08\n",
      "aircraft carrier 4.54295729923615e-08\n",
      "horse cart 4.520208207736687e-08\n",
      "hammerhead 4.477364967669928e-08\n",
      "cardoon 4.425100641469726e-08\n",
      "box turtle 4.417923804567181e-08\n",
      "bighorn 4.415160859139178e-08\n",
      "sea lion 4.403949560582987e-08\n",
      "ski mask 4.390739860582471e-08\n",
      "German short-haired pointer 4.345475090872242e-08\n",
      "bald eagle 4.2394720622951354e-08\n",
      "toaster 4.201724834729248e-08\n",
      "beaker 4.194630420784051e-08\n",
      "desk 4.1547540519104587e-08\n",
      "garden spider 4.134366804464662e-08\n",
      "zebra 4.1301895237211284e-08\n",
      "Weimaraner 4.0538985501825664e-08\n",
      "scuba diver 3.9548041286252555e-08\n",
      "space shuttle 3.9222392445026344e-08\n",
      "oil filter 3.722997732324984e-08\n",
      "kite 3.7138558894866947e-08\n",
      "earthstar 3.6560475535907244e-08\n",
      "conch 3.5750353788444045e-08\n",
      "bison 3.563387807048457e-08\n",
      "sloth bear 3.530831804710033e-08\n",
      "little blue heron 3.518019298098807e-08\n",
      "bathing cap 3.498813683222579e-08\n",
      "pickelhaube 3.477457255485206e-08\n",
      "whiptail 3.429975947710773e-08\n",
      "pencil sharpener 3.336019815947111e-08\n",
      "wolf spider 3.322982067288649e-08\n",
      "lycaenid 3.298845996368982e-08\n",
      "hornbill 3.285922645090977e-08\n",
      "garter snake 3.165277107086695e-08\n",
      "hip 3.134636017421144e-08\n",
      "bull mastiff 3.1199267169768063e-08\n",
      "bustard 3.0663706240829924e-08\n",
      "confectionery 3.060854680825287e-08\n",
      "Bedlington terrier 2.9834215098389905e-08\n",
      "European gallinule 2.96024964541175e-08\n",
      "bee 2.7457845774847556e-08\n",
      "slide rule 2.712604718624334e-08\n",
      "freight car 2.6892680082823972e-08\n",
      "mud turtle 2.6694753074707478e-08\n",
      "cabbage butterfly 2.651288966148968e-08\n",
      "crane 2.6389285423533693e-08\n",
      "cello 2.6208805792293788e-08\n",
      "digital watch 2.6202654268558945e-08\n",
      "consomme 2.614434890801931e-08\n",
      "pool table 2.5980254392266033e-08\n",
      "green snake 2.5963810657003705e-08\n",
      "bookshop 2.5714776086260827e-08\n",
      "macaw 2.5471969422596885e-08\n",
      "gorilla 2.5217214982831138e-08\n",
      "oystercatcher 2.518500963333281e-08\n",
      "tiger shark 2.4906698925519777e-08\n",
      "puffer 2.4807894405398656e-08\n",
      "vault 2.4799094333616267e-08\n",
      "chambered nautilus 2.443525737305663e-08\n",
      "academic gown 2.4228921091662414e-08\n",
      "sewing machine 2.4200838666388336e-08\n",
      "dining table 2.356841655171138e-08\n",
      "guillotine 2.3477651822645385e-08\n",
      "menu 2.3340668064975034e-08\n",
      "rubber eraser 2.2622336004474164e-08\n",
      "bolete 2.231991835799363e-08\n",
      "lorikeet 2.2114102549153358e-08\n",
      "agama 2.177893776433848e-08\n",
      "bullet train 2.146072120012832e-08\n",
      "tarantula 2.091908868351311e-08\n",
      "streetcar 2.056230741231957e-08\n",
      "volleyball 2.03250358765672e-08\n",
      "fig 1.9981436949478848e-08\n",
      "black widow 1.9070711232416215e-08\n",
      "library 1.8996432871176694e-08\n",
      "great grey owl 1.8854356298447783e-08\n",
      "jellyfish 1.8638463217257595e-08\n",
      "chimpanzee 1.8469659579523068e-08\n",
      "green mamba 1.834652607612952e-08\n",
      "water tower 1.825322826221054e-08\n",
      "potter's wheel 1.8244039168280324e-08\n",
      "water ouzel 1.7967289878129122e-08\n",
      "mantis 1.7822776143816554e-08\n",
      "siamang 1.781088165841993e-08\n",
      "impala 1.772270685762578e-08\n",
      "restaurant 1.749376110637968e-08\n",
      "dome 1.7481486480619424e-08\n",
      "drake 1.7188252598998588e-08\n",
      "goldfinch 1.6937983460252326e-08\n",
      "bell pepper 1.6760298038320798e-08\n",
      "prison 1.652136383256675e-08\n",
      "hourglass 1.5991354018751736e-08\n",
      "triumphal arch 1.5850634582648127e-08\n",
      "apiary 1.526059989487294e-08\n",
      "mosque 1.4637731027278278e-08\n",
      "balance beam 1.4329226694087538e-08\n",
      "hippopotamus 1.394418358557914e-08\n",
      "warthog 1.3935382625618331e-08\n",
      "barn spider 1.3816681132539088e-08\n",
      "basketball 1.3768461037955149e-08\n",
      "rock beauty 1.372731794901938e-08\n",
      "cicada 1.3587303726581013e-08\n",
      "ladybug 1.2951575811825933e-08\n",
      "black-and-tan coonhound 1.2708994745480595e-08\n",
      "ringlet 1.2525450898692725e-08\n",
      "black stork 1.2508118985010697e-08\n",
      "container ship 1.2122590042906722e-08\n",
      "Arabian camel 1.1684806011658111e-08\n",
      "hermit crab 1.1382951470295666e-08\n",
      "redshank 1.1378805453432506e-08\n",
      "leaf beetle 1.1325734128320164e-08\n",
      "lionfish 1.1253384002429812e-08\n",
      "limpkin 1.0980294007367775e-08\n",
      "flamingo 1.0641674208500262e-08\n",
      "tusker 1.063643839671613e-08\n",
      "loggerhead 1.0593051769092199e-08\n",
      "platypus 1.0575064379736432e-08\n",
      "espresso maker 1.0572361652805284e-08\n",
      "cheeseburger 1.0162803931734743e-08\n",
      "cliff dwelling 1.0065480893217682e-08\n",
      "harvestman 9.940020362364521e-09\n",
      "dung beetle 9.855370741718161e-09\n",
      "potpie 9.797792799304261e-09\n",
      "coucal 9.569020242850002e-09\n",
      "toyshop 9.35941457669287e-09\n",
      "parallel bars 9.108453546957662e-09\n",
      "admiral 9.089138330864444e-09\n",
      "monastery 8.903890957867588e-09\n",
      "coral reef 8.876319235184837e-09\n",
      "plane 8.874661006075257e-09\n",
      "sea snake 8.789102778905544e-09\n",
      "American coot 8.472720303132064e-09\n",
      "butcher shop 8.462883727133885e-09\n",
      "altar 8.357749159415562e-09\n",
      "throne 7.879267904797871e-09\n",
      "monarch 7.63702256989518e-09\n",
      "stinkhorn 7.582564798269686e-09\n",
      "boa constrictor 7.2129844319590575e-09\n",
      "trilobite 7.092656684193344e-09\n",
      "police van 7.032951998553472e-09\n",
      "hummingbird 6.875618296930952e-09\n",
      "brain coral 6.221350101753842e-09\n",
      "electric locomotive 6.161724908082533e-09\n",
      "proboscis monkey 5.902379474065356e-09\n",
      "junco 5.622065479826688e-09\n",
      "nematode 5.619653187238782e-09\n",
      "Indian cobra 5.073264919275289e-09\n",
      "jinrikisha 4.948790710557205e-09\n",
      "Indian elephant 4.602646708207203e-09\n",
      "robin 4.570602119002842e-09\n",
      "chickadee 4.5330099673890345e-09\n",
      "dowitcher 4.018751997847403e-09\n",
      "trolleybus 3.9380165794966615e-09\n",
      "bittern 3.811545745691092e-09\n",
      "espresso 3.6860772212321535e-09\n",
      "drilling platform 3.4250451363959655e-09\n",
      "fiddler crab 3.327477626768882e-09\n",
      "hartebeest 3.2789027049062724e-09\n",
      "comic book 3.1814966217069696e-09\n",
      "bee eater 2.9608577811757186e-09\n",
      "red-breasted merganser 2.908062457507299e-09\n",
      "hot pot 2.3665704951270072e-09\n",
      "tiger beetle 2.289981759773241e-09\n",
      "damselfly 2.275938992823967e-09\n",
      "vestment 2.010881683389698e-09\n",
      "indigo bunting 1.715670050472795e-09\n",
      "fly 1.5831682631528565e-09\n",
      "jacamar 1.541096805723896e-09\n",
      "dragonfly 1.3297963841196747e-09\n",
      "red-backed sandpiper 8.629860714925996e-10\n",
      "African elephant 8.254641969962506e-10\n",
      "brambling 5.636181521495587e-10\n",
      "gyromitra 5.214872977887808e-10\n",
      "ruddy turnstone 2.3851715047484845e-10\n",
      "house finch 1.6867490737482171e-10\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 1000)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118557090719\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [34], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m prediction \u001b[39m=\u001b[39m model(batch)\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39msoftmax(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m     58\u001b[0m class_id \u001b[39m=\u001b[39m prediction\u001b[39m.\u001b[39margmax()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> 59\u001b[0m score \u001b[39m=\u001b[39m prediction[class_id]\u001b[39m.\u001b[39;49mitem()\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m     60\u001b[0m category_name \u001b[39m=\u001b[39m weights\u001b[39m.\u001b[39mmeta[\u001b[39m\"\u001b[39m\u001b[39mcategories\u001b[39m\u001b[39m\"\u001b[39m][class_id]\n\u001b[1;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcategory_name\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m score\u001b[39m:\u001b[39;00m\u001b[39m.1f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights \n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "path = '/home/nclhpm/Desktop/Teymoor/CNNBenchmark/RESNET50/Dataset/'\n",
    "img_names = os.listdir(path)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#command = 'sudo ./test.sh -S Fri16Sep'\n",
    "#process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
    "#output, error = process.communicate()\n",
    "#torch.cuda.is_available = lambda : False\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "sudo_password = 'Fri16Sep'\n",
    "command = 'sudo ./test.sh'\n",
    "command = command.split()\n",
    "\n",
    "cmd1 = subprocess.Popen(['echo',sudo_password], stdout=subprocess.PIPE)\n",
    "cmd2 = subprocess.Popen(['sudo','-S'] + command, stdin=cmd1.stdout, stdout=subprocess.PIPE)\n",
    "\n",
    "output = cmd2.stdout.read().decode() \n",
    "print(output)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "for idx, name in enumerate(img_names):\n",
    "    start = time.time()\n",
    "    img_name = path + name\n",
    "    # Use you favourite library to load the image\n",
    "    img = read_image(img_name)\n",
    "    weights = MobileNet_V2_Weights.DEFAULT\n",
    "    model = mobilenet_v2(weights=weights)\n",
    "    model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "    batch = preprocess(img).unsqueeze(0).cpu()\n",
    "   \n",
    "    if torch.cuda.is_available():\n",
    "      batch = batch.to('cuda')\n",
    "      model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "      output = model(batch)\n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "      #print(output[0])\n",
    "   \n",
    "    # Step 4: Use the model and print the predicted category\n",
    "    end = time.time()\n",
    "    prediction = model(batch).squeeze(0).softmax(0).cpu()\n",
    "    class_id = prediction.argmax().item()\n",
    "    score = prediction[class_id].item()\n",
    "    category_name = weights.meta[\"categories\"][class_id]\n",
    "    print(f\"{category_name}: {100 * score:.1f}%\")\n",
    "    print(img_name)\n",
    "    print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "sudo_password = 'Fri16Sep'\n",
    "command = 'sudo ./test.sh'\n",
    "command = command.split()\n",
    "\n",
    "cmd1 = subprocess.Popen(['echo',sudo_password], stdout=subprocess.PIPE)\n",
    "cmd2 = subprocess.Popen(['sudo','-S'] + command, stdin=cmd1.stdout, stdout=subprocess.PIPE)\n",
    "\n",
    "output = cmd2.stdout.read().decode() \n",
    "print(output)\n",
    "        #image = plt.imread(img_name)\n",
    "        #images[idx] = image\n",
    "\n",
    "    #img = read_image(\"dog.jpg\")\n",
    "\n",
    "    # Step 1: Initialize model with the best available weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msubprocess\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m#command = 'sudo ./test.sh -S Fri16Sep'\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m#process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m#output, error = process.communicate()\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m sudo_password \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFri16Sep\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     20\u001b[0m command \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msudo ./test.sh\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "path = '/home/nclhpm/Desktop/Teymoor/CNNBenchmark/RESNET50/Dataset/'\n",
    "img_names = os.listdir(path)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#command = 'sudo ./test.sh -S Fri16Sep'\n",
    "#process = subprocess.Popen(command.split(), stdout=subprocess.PIPE)\n",
    "#output, error = process.communicate()\n",
    "\n",
    "sudo_password = 'Fri16Sep'\n",
    "command = 'sudo ./test.sh'\n",
    "command = command.split()\n",
    "\n",
    "cmd1 = subprocess.Popen(['echo',sudo_password], stdout=subprocess.PIPE)\n",
    "cmd2 = subprocess.Popen(['sudo','-S'] + command, stdin=cmd1.stdout, stdout=subprocess.PIPE)\n",
    "\n",
    "output = cmd2.stdout.read().decode() \n",
    "print(output)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "for idx, name in enumerate(img_names):\n",
    "    start = time.time()\n",
    "    img_name = path + name\n",
    "    # Use you favourite library to load the image\n",
    "    img = read_image(img_name)\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights)\n",
    "    model.eval()\n",
    "\n",
    "# Step 2: Initialize the inference transforms\n",
    "    preprocess = weights.transforms()\n",
    "\n",
    "# Step 3: Apply inference preprocessing transforms\n",
    "    batch = preprocess(img).unsqueeze(0)\n",
    "    \n",
    "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
    "      #print(output[0])\n",
    "   \n",
    "    # Step 4: Use the model and print the predicted category\n",
    "    end = time.time()\n",
    "    prediction = model(batch).squeeze(0).softmax(0)\n",
    "    class_id = prediction.argmax().item()\n",
    "    score = prediction[class_id].item()\n",
    "    category_name = weights.meta[\"categories\"][class_id]\n",
    "    print(f\"{category_name}: {100 * score:.1f}%\")\n",
    "    print(img_name)\n",
    "    print(end - start)\n",
    "\n",
    "\n",
    "\n",
    "sudo_password = 'Fri16Sep'\n",
    "command = 'sudo ./test.sh'\n",
    "command = command.split()\n",
    "\n",
    "cmd1 = subprocess.Popen(['echo',sudo_password], stdout=subprocess.PIPE)\n",
    "cmd2 = subprocess.Popen(['sudo','-S'] + command, stdin=cmd1.stdout, stdout=subprocess.PIPE)\n",
    "\n",
    "output = cmd2.stdout.read().decode() \n",
    "print(output)\n",
    "        #image = plt.imread(img_name)\n",
    "        #images[idx] = image\n",
    "\n",
    "    #img = read_image(\"dog.jpg\")\n",
    "\n",
    "    # Step 1: Initialize model with the best available weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
